{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2015, Google DeepMind ([Link](https://deepmind.com/research/dqn/)) published a paper in Nature magazine that combines a deep convolution neural network with reinforcement learning for the first time in order to master a range of Atari 2600 games. They used only the raw pixels and score as the inputs. They were able to use the convolution layer to translate the pixels.  \n",
    "\n",
    "The very simple description is that they replaced the Q table in a Q-Learner with a neural network. This allowed them to take advantage of neural networks but still use reinforcement learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8aa8692375f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#from keras.models import Sequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#from keras.layers import Dense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "#Create Gym\n",
    "from gym import wrappers\n",
    "envCartPole = gym.make('CartPole-v1')\n",
    "envCartPole.seed(50) #Set the seed to keep the environment consistent across runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience Replay**  \n",
    "Definition: A mechanism inspired by biology that randomizes over the data removing the correlation in the observation sequence and smoothing over changes in the data distribution.  \n",
    "\n",
    "To perform an experience replay, the algorithm stores all of the agents experiences {$s_t,a_t,r_t,s_{t+1}$} at each time step in a data set. Normally in a q-learner, we would run the update rule on them. But, with experience replay we just store them.  \n",
    "\n",
    "Later during the training process these replays will be drawn uniformly from the memory queue and be ran through the update rule. There are 2 ways to handle this and I have coded both in the past. The first is to run them on every loop and the other is to run them after X amount of runs. In this code below, I run them each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side Track: Vectorization**  \n",
    "I am going to take some time to talk about vectorization. If you are experienced with python you can skip this part. But, I went from running 100 episodes in mutliple minutes to being able to run 500 in less than 1.  \n",
    "\n",
    "The idea is that you execute the same task on ALL entries in an array at the same time.  \n",
    "\n",
    "Old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n"
     ]
    }
   ],
   "source": [
    "tmp_array = []\n",
    "for i in range(100):\n",
    "    tmp_array.append(i)\n",
    "    \n",
    "#Add 10 to each element\n",
    "for i in range(100):\n",
    "    tmp_array[i] += 10\n",
    "print(tmp_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109]\n"
     ]
    }
   ],
   "source": [
    "tmp_array = []\n",
    "for i in range(100):\n",
    "    tmp_array.append(i)\n",
    "    \n",
    "#Add 10 to each element\n",
    "tmp_array = np.array(tmp_array) + 10\n",
    "print(tmp_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these vectorizations will be calling a method versus just adding 10 but this is a simple solution. You will see a TREMENDOUS speed up avoiding the loops in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CartPole Example**  \n",
    "Again we will use the [CartPole](https://gym.openai.com/envs/CartPole-v1/) environment from OpenAI.  \n",
    "\n",
    "The actions are 0 to push the cart to the left and 1 to push the cart to the right.  \n",
    "\n",
    "The continuous state space is an X coordinate for location, the velocity of the cart, the angle of the pole, and the velocity at the tip of the pole. The X coordinate goes from -4.8 to +4.8, velocity is -Inf to +Inf, angle of the pole goes from -24 degrees to +24 degrees, tip velocity is -Inf to +Inf. With all of the possible combinations you can see why we can't create a Q table for each one.  \n",
    "\n",
    "To \"solve\" this puzzle you have to have an average reward of > 195 over 100 consecutive episodes. One thing to note, I am hard capping the rewards at 210 so this number can't average above that and it also could potentially drive the average down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "EPISODES = 500\n",
    "TRAIN_END = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "def discount_rate(): #Gamma\n",
    "    return 0.95\n",
    "\n",
    "def learning_rate(): #Alpha\n",
    "    return 0.001\n",
    "\n",
    "def batch_size(): #Size of the batch used in the experience replay\n",
    "    return 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Q-Network Class**  \n",
    "The following class is the deep Q-network that is built using the neural network code from Keras.  \n",
    "**init**:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This creates the class and sets the local parameters.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I use a *deque* for the local memory to hold the experiences and a keras model for the NN.  \n",
    "\n",
    "**build_model(self)**:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This builds the NN. I am using sequential model. Each of the layers are *Dense* despite the fact the document talks about using *Convolution*. But, they are only using that because they need to convert pixels and I already have numbers.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I am using an input layer(4), 24 neuron layer, 24 neuron layer, and an output layer(2).  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For calculating the loss I am using mean squared error.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For an optimizer I am using [Adam](https://arxiv.org/abs/1412.6980v8). It is a variant of gradient descent and you can read the technical document at the link. If you want a slightly lighter explaining you can check out [Machine Learning Mastery](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/). You could also use SGD (Stochastic Gradient Descent) but Adam gives me better results and seems to be the standard in most examples.  \n",
    "\n",
    "**action(self,state)**:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This generates the action.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Explore: I am using the epsilon like previous lessons.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Exploit: I use the NN to grab the 2 possible actions and then grab the argmax to find the better one  \n",
    "\n",
    "**test_action(self,state)**:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This generates the action when I am testing. I want to 100% exploit  \n",
    "\n",
    "**store(self, state, action, reward, nstate, done)**:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This places the observables in memory  \n",
    "\n",
    "**experience_replay(self, batch_size)**:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This is where the training occurs. We grab the sample batches and then use the NN to predict the optimal action.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork():\n",
    "    def __init__(self, states, actions, alpha, gamma, epsilon,epsilon_min, epsilon_decay):\n",
    "        self.nS = states\n",
    "        self.nA = actions\n",
    "        self.memory = deque([], maxlen=2500)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        #Explore/Exploit\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.model = self.build_model()\n",
    "        self.loss = []\n",
    "        \n",
    "    def build_model(self):\n",
    "        model = keras.Sequential() #linear stack of layers https://keras.io/models/sequential/\n",
    "        model.add(keras.layers.Dense(24, input_dim=self.nS, activation='relu')) #[Input] -> Layer 1\n",
    "        #   Dense: Densely connected layer https://keras.io/layers/core/\n",
    "        #   24: Number of neurons\n",
    "        #   input_dim: Number of input variables\n",
    "        #   activation: Rectified Linear Unit (relu) ranges >= 0\n",
    "        model.add(keras.layers.Dense(24, activation='relu')) #Layer 2 -> 3\n",
    "        model.add(keras.layers.Dense(self.nA, activation='linear')) #Layer 3 -> [output]\n",
    "        #   Size has to match the output (different actions)\n",
    "        #   Linear activation on the last layer\n",
    "        model.compile(loss='mean_squared_error', #Loss function: Mean Squared Error\n",
    "                      optimizer=keras.optimizers.Adam(lr=self.alpha)) #Optimaizer: Adam (Feel free to check other options)\n",
    "        return model\n",
    "\n",
    "    def action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.nA) #Explore\n",
    "        action_vals = self.model.predict(state) #Exploit: Use the NN to predict the correct action from this state\n",
    "        return np.argmax(action_vals[0])\n",
    "\n",
    "    def test_action(self, state): #Exploit\n",
    "        action_vals = self.model.predict(state)\n",
    "        return np.argmax(action_vals[0])\n",
    "\n",
    "    def store(self, state, action, reward, nstate, done):\n",
    "        #Store the experience in memory\n",
    "        self.memory.append( (state, action, reward, nstate, done) )\n",
    "\n",
    "    def experience_replay(self, batch_size):\n",
    "        #Execute the experience replay\n",
    "        minibatch = random.sample( self.memory, batch_size ) #Randomly sample from memory\n",
    "\n",
    "        #Convert to numpy for speed by vectorization\n",
    "        x = []\n",
    "        y = []\n",
    "        np_array = np.array(minibatch)\n",
    "        st = np.zeros((0,self.nS)) #States\n",
    "        nst = np.zeros( (0,self.nS) )#Next States\n",
    "        for i in range(len(np_array)): #Creating the state and next state np arrays\n",
    "            st = np.append( st, np_array[i,0], axis=0)\n",
    "            nst = np.append( nst, np_array[i,3], axis=0)\n",
    "        st_predict = self.model.predict(st) #Here is the speedup! I can predict on the ENTIRE batch\n",
    "        nst_predict = self.model.predict(nst)\n",
    "        index = 0\n",
    "        for state, action, reward, nstate, done in minibatch:\n",
    "            x.append(state)\n",
    "            #Predict from state\n",
    "            nst_action_predict_model = nst_predict[index]\n",
    "            if done == True: #Terminal: Just assign reward much like {* (not done) - QB[state][action]}\n",
    "                target = reward\n",
    "            else:   #Non terminal\n",
    "                target = reward + self.gamma * np.amax(nst_action_predict_model)\n",
    "            target_f = st_predict[index]\n",
    "            target_f[action] = target\n",
    "            y.append(target_f)\n",
    "            index += 1\n",
    "        #Reshape for Keras Fit\n",
    "        x_reshape = np.array(x).reshape(batch_size,self.nS)\n",
    "        y_reshape = np.array(y)\n",
    "        epoch_count = 1 #Epochs is the number or iterations\n",
    "        hist = self.model.fit(x_reshape, y_reshape, epochs=epoch_count, verbose=0)\n",
    "        #Graph Losses\n",
    "        for i in range(epoch_count):\n",
    "            self.loss.append( hist.history['loss'][i] )\n",
    "        #Decay Epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the agent\n",
    "nS = envCartPole.observation_space.shape[0] #This is only 4\n",
    "nA = envCartPole.action_space.n #Actions\n",
    "dqn = DeepQNetwork(nS, nA, learning_rate(), discount_rate(), 1, 0.001, 0.995 )\n",
    "\n",
    "batch_size = batch_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/500, score: 16.0, e: 1\n",
      "episode: 1/500, score: 23.0, e: 0.9322301194154049\n",
      "episode: 2/500, score: 21.0, e: 0.8433051360508336\n",
      "episode: 3/500, score: 37.0, e: 0.7040696960536299\n",
      "episode: 4/500, score: 19.0, e: 0.6433260027715241\n",
      "episode: 5/500, score: 15.0, e: 0.5997278763867329\n",
      "episode: 6/500, score: 10.0, e: 0.5732736268885887\n",
      "episode: 7/500, score: 17.0, e: 0.5290920728090721\n",
      "episode: 8/500, score: 9.0, e: 0.5082950737585841\n",
      "episode: 9/500, score: 19.0, e: 0.46444185833082485\n",
      "episode: 10/500, score: 14.0, e: 0.4351424010585501\n",
      "episode: 11/500, score: 11.0, e: 0.41386834584198684\n",
      "episode: 12/500, score: 13.0, e: 0.3897078735047413\n",
      "episode: 13/500, score: 15.0, e: 0.3632974174544486\n",
      "episode: 14/500, score: 9.0, e: 0.34901730169741024\n",
      "episode: 15/500, score: 12.0, e: 0.3302941218954743\n",
      "episode: 16/500, score: 18.0, e: 0.3033145315372582\n",
      "episode: 17/500, score: 9.0, e: 0.2913921604631864\n",
      "episode: 18/500, score: 20.0, e: 0.2649210072611673\n",
      "episode: 19/500, score: 15.0, e: 0.24696734223472733\n",
      "episode: 20/500, score: 14.0, e: 0.231387331601191\n",
      "episode: 21/500, score: 10.0, e: 0.2211807388415433\n",
      "episode: 22/500, score: 11.0, e: 0.21036724137609603\n",
      "episode: 23/500, score: 11.0, e: 0.2000824143909432\n",
      "episode: 24/500, score: 10.0, e: 0.1912566947289212\n",
      "episode: 25/500, score: 9.0, e: 0.18373897616330553\n",
      "episode: 26/500, score: 9.0, e: 0.17651675623376062\n",
      "episode: 27/500, score: 11.0, e: 0.1678868750508869\n",
      "episode: 28/500, score: 25.0, e: 0.14885748713096328\n",
      "episode: 29/500, score: 9.0, e: 0.14300635237083656\n",
      "episode: 30/500, score: 10.0, e: 0.13669828187021155\n",
      "episode: 31/500, score: 11.0, e: 0.13001512070402377\n",
      "episode: 32/500, score: 9.0, e: 0.12490462201997637\n",
      "episode: 33/500, score: 9.0, e: 0.11999500148501063\n",
      "episode: 34/500, score: 74.0, e: 0.0832238973628649\n",
      "episode: 35/500, score: 24.0, e: 0.07416156859737154\n",
      "episode: 36/500, score: 19.0, e: 0.0677632708131484\n",
      "episode: 37/500, score: 31.0, e: 0.05830244700006734\n",
      "episode: 38/500, score: 23.0, e: 0.052214913061211746\n",
      "episode: 39/500, score: 27.0, e: 0.04583472801998072\n",
      "episode: 40/500, score: 29.0, e: 0.03983280768576652\n",
      "episode: 41/500, score: 51.0, e: 0.03100237440513238\n",
      "episode: 42/500, score: 15.0, e: 0.028901347193857643\n",
      "episode: 43/500, score: 30.0, e: 0.024991218342344988\n",
      "episode: 44/500, score: 49.0, e: 0.01964695745288379\n",
      "episode: 45/500, score: 19.0, e: 0.017951913959130504\n",
      "episode: 46/500, score: 29.0, e: 0.015601164601953134\n",
      "episode: 47/500, score: 22.0, e: 0.014042412118399107\n",
      "episode: 48/500, score: 15.0, e: 0.013090759526015528\n",
      "episode: 49/500, score: 32.0, e: 0.011206767143558775\n",
      "episode: 50/500, score: 126.0, e: 0.005989153463270236\n",
      "episode: 51/500, score: 88.0, e: 0.003872339856794843\n",
      "episode: 52/500, score: 51.0, e: 0.003013890735780812\n",
      "episode: 53/500, score: 34.0, e: 0.0025544015447035015\n",
      "episode: 54/500, score: 116.0, e: 0.001435302541686172\n",
      "episode: 55/500, score: 103.0, e: 0.0009954703940636294\n",
      "episode: 56/500, score: 109.0, e: 0.0009954703940636294\n",
      "episode: 57/500, score: 54.0, e: 0.0009954703940636294\n",
      "episode: 58/500, score: 72.0, e: 0.0009954703940636294\n",
      "episode: 59/500, score: 53.0, e: 0.0009954703940636294\n",
      "episode: 60/500, score: 80.0, e: 0.0009954703940636294\n",
      "episode: 61/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 62/500, score: 134.0, e: 0.0009954703940636294\n",
      "episode: 63/500, score: 117.0, e: 0.0009954703940636294\n",
      "episode: 64/500, score: 123.0, e: 0.0009954703940636294\n",
      "episode: 65/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 66/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 67/500, score: 158.0, e: 0.0009954703940636294\n",
      "episode: 68/500, score: 67.0, e: 0.0009954703940636294\n",
      "episode: 69/500, score: 58.0, e: 0.0009954703940636294\n",
      "episode: 70/500, score: 87.0, e: 0.0009954703940636294\n",
      "episode: 71/500, score: 138.0, e: 0.0009954703940636294\n",
      "episode: 72/500, score: 56.0, e: 0.0009954703940636294\n",
      "episode: 73/500, score: 50.0, e: 0.0009954703940636294\n",
      "episode: 74/500, score: 67.0, e: 0.0009954703940636294\n",
      "episode: 75/500, score: 54.0, e: 0.0009954703940636294\n",
      "episode: 76/500, score: 50.0, e: 0.0009954703940636294\n",
      "episode: 77/500, score: 74.0, e: 0.0009954703940636294\n",
      "episode: 78/500, score: 66.0, e: 0.0009954703940636294\n",
      "episode: 79/500, score: 59.0, e: 0.0009954703940636294\n",
      "episode: 80/500, score: 53.0, e: 0.0009954703940636294\n",
      "episode: 81/500, score: 170.0, e: 0.0009954703940636294\n",
      "episode: 82/500, score: 98.0, e: 0.0009954703940636294\n",
      "episode: 83/500, score: 77.0, e: 0.0009954703940636294\n",
      "episode: 84/500, score: 139.0, e: 0.0009954703940636294\n",
      "episode: 85/500, score: 74.0, e: 0.0009954703940636294\n",
      "episode: 86/500, score: 121.0, e: 0.0009954703940636294\n",
      "episode: 87/500, score: 160.0, e: 0.0009954703940636294\n",
      "episode: 88/500, score: 117.0, e: 0.0009954703940636294\n",
      "episode: 89/500, score: 178.0, e: 0.0009954703940636294\n",
      "episode: 90/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 91/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 92/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 93/500, score: 159.0, e: 0.0009954703940636294\n",
      "episode: 94/500, score: 136.0, e: 0.0009954703940636294\n",
      "episode: 95/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 96/500, score: 169.0, e: 0.0009954703940636294\n",
      "episode: 97/500, score: 188.0, e: 0.0009954703940636294\n",
      "episode: 98/500, score: 158.0, e: 0.0009954703940636294\n",
      "episode: 99/500, score: 157.0, e: 0.0009954703940636294\n",
      "episode: 100/500, score: 150.0, e: 0.0009954703940636294\n",
      "episode: 101/500, score: 139.0, e: 0.0009954703940636294\n",
      "episode: 102/500, score: 153.0, e: 0.0009954703940636294\n",
      "episode: 103/500, score: 139.0, e: 0.0009954703940636294\n",
      "episode: 104/500, score: 145.0, e: 0.0009954703940636294\n",
      "episode: 105/500, score: 161.0, e: 0.0009954703940636294\n",
      "episode: 106/500, score: 189.0, e: 0.0009954703940636294\n",
      "episode: 107/500, score: 180.0, e: 0.0009954703940636294\n",
      "episode: 108/500, score: 165.0, e: 0.0009954703940636294\n",
      "episode: 109/500, score: 161.0, e: 0.0009954703940636294\n",
      "episode: 110/500, score: 191.0, e: 0.0009954703940636294\n",
      "episode: 111/500, score: 170.0, e: 0.0009954703940636294\n",
      "episode: 112/500, score: 168.0, e: 0.0009954703940636294\n",
      "episode: 113/500, score: 148.0, e: 0.0009954703940636294\n",
      "episode: 114/500, score: 174.0, e: 0.0009954703940636294\n",
      "episode: 115/500, score: 164.0, e: 0.0009954703940636294\n",
      "episode: 116/500, score: 189.0, e: 0.0009954703940636294\n",
      "episode: 117/500, score: 171.0, e: 0.0009954703940636294\n",
      "episode: 118/500, score: 169.0, e: 0.0009954703940636294\n",
      "episode: 119/500, score: 189.0, e: 0.0009954703940636294\n",
      "episode: 120/500, score: 167.0, e: 0.0009954703940636294\n",
      "episode: 121/500, score: 168.0, e: 0.0009954703940636294\n",
      "episode: 122/500, score: 198.0, e: 0.0009954703940636294\n",
      "episode: 123/500, score: 177.0, e: 0.0009954703940636294\n",
      "episode: 124/500, score: 194.0, e: 0.0009954703940636294\n",
      "episode: 125/500, score: 196.0, e: 0.0009954703940636294\n",
      "episode: 126/500, score: 201.0, e: 0.0009954703940636294\n",
      "episode: 127/500, score: 185.0, e: 0.0009954703940636294\n",
      "episode: 128/500, score: 175.0, e: 0.0009954703940636294\n",
      "episode: 129/500, score: 210.0, e: 0.0009954703940636294\n",
      "episode: 130/500, score: 195.0, e: 0.0009954703940636294\n",
      "episode: 131/500, score: 175.0, e: 0.0009954703940636294\n",
      "episode: 132/500, score: 208.0, e: 0.0009954703940636294\n",
      "episode: 133/500, score: 210.0, e: 0.0009954703940636294\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "rewards = [] #Store rewards for graphing\n",
    "epsilons = [] # Store the Explore/Exploit\n",
    "TEST_Episodes = 0\n",
    "for e in range(EPISODES):\n",
    "    state = envCartPole.reset()\n",
    "    state = np.reshape(state, [1, nS]) # Resize to store in memory to pass to .predict\n",
    "    tot_rewards = 0\n",
    "    for time in range(210): #200 is when you \"solve\" the game. This can continue forever as far as I know\n",
    "        action = dqn.action(state)\n",
    "        nstate, reward, done, _ = envCartPole.step(action)\n",
    "        nstate = np.reshape(nstate, [1, nS])\n",
    "        tot_rewards += reward\n",
    "        dqn.store(state, action, reward, nstate, done) # Resize to store in memory to pass to .predict\n",
    "        state = nstate\n",
    "        #done: CartPole fell. \n",
    "        #time == 209: CartPole stayed upright\n",
    "        if done or time == 209:\n",
    "            rewards.append(tot_rewards)\n",
    "            epsilons.append(dqn.epsilon)\n",
    "            print(\"episode: {}/{}, score: {}, e: {}\"\n",
    "                  .format(e, EPISODES, tot_rewards, dqn.epsilon))\n",
    "            break\n",
    "        #Experience Replay\n",
    "        if len(dqn.memory) > batch_size:\n",
    "            dqn.experience_replay(batch_size)\n",
    "    #If our current NN passes we are done\n",
    "    #I am going to use the last 5 runs\n",
    "    if len(rewards) > 5 and np.average(rewards[-5:]) > 195:\n",
    "        #Set the rest of the EPISODES for testing\n",
    "        TEST_Episodes = EPISODES - e\n",
    "        TRAIN_END = e\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/367, score: 205.0, e: 0\n",
      "episode: 1/367, score: 210.0, e: 0\n",
      "episode: 2/367, score: 210.0, e: 0\n",
      "episode: 3/367, score: 210.0, e: 0\n",
      "episode: 4/367, score: 210.0, e: 0\n",
      "episode: 5/367, score: 193.0, e: 0\n",
      "episode: 6/367, score: 210.0, e: 0\n",
      "episode: 7/367, score: 210.0, e: 0\n",
      "episode: 8/367, score: 198.0, e: 0\n",
      "episode: 9/367, score: 210.0, e: 0\n",
      "episode: 10/367, score: 210.0, e: 0\n",
      "episode: 11/367, score: 210.0, e: 0\n",
      "episode: 12/367, score: 180.0, e: 0\n",
      "episode: 13/367, score: 210.0, e: 0\n",
      "episode: 14/367, score: 209.0, e: 0\n",
      "episode: 15/367, score: 204.0, e: 0\n",
      "episode: 16/367, score: 210.0, e: 0\n",
      "episode: 17/367, score: 210.0, e: 0\n",
      "episode: 18/367, score: 210.0, e: 0\n",
      "episode: 19/367, score: 210.0, e: 0\n",
      "episode: 20/367, score: 183.0, e: 0\n",
      "episode: 21/367, score: 208.0, e: 0\n",
      "episode: 22/367, score: 210.0, e: 0\n",
      "episode: 23/367, score: 188.0, e: 0\n",
      "episode: 24/367, score: 210.0, e: 0\n",
      "episode: 25/367, score: 198.0, e: 0\n",
      "episode: 26/367, score: 210.0, e: 0\n",
      "episode: 27/367, score: 210.0, e: 0\n",
      "episode: 28/367, score: 210.0, e: 0\n",
      "episode: 29/367, score: 210.0, e: 0\n",
      "episode: 30/367, score: 197.0, e: 0\n",
      "episode: 31/367, score: 210.0, e: 0\n",
      "episode: 32/367, score: 210.0, e: 0\n",
      "episode: 33/367, score: 210.0, e: 0\n",
      "episode: 34/367, score: 198.0, e: 0\n",
      "episode: 35/367, score: 208.0, e: 0\n",
      "episode: 36/367, score: 210.0, e: 0\n",
      "episode: 37/367, score: 210.0, e: 0\n",
      "episode: 38/367, score: 210.0, e: 0\n",
      "episode: 39/367, score: 200.0, e: 0\n",
      "episode: 40/367, score: 210.0, e: 0\n",
      "episode: 41/367, score: 210.0, e: 0\n",
      "episode: 42/367, score: 210.0, e: 0\n",
      "episode: 43/367, score: 204.0, e: 0\n",
      "episode: 44/367, score: 199.0, e: 0\n",
      "episode: 45/367, score: 210.0, e: 0\n",
      "episode: 46/367, score: 192.0, e: 0\n",
      "episode: 47/367, score: 210.0, e: 0\n",
      "episode: 48/367, score: 210.0, e: 0\n",
      "episode: 49/367, score: 210.0, e: 0\n",
      "episode: 50/367, score: 193.0, e: 0\n",
      "episode: 51/367, score: 210.0, e: 0\n",
      "episode: 52/367, score: 210.0, e: 0\n",
      "episode: 53/367, score: 209.0, e: 0\n",
      "episode: 54/367, score: 210.0, e: 0\n",
      "episode: 55/367, score: 176.0, e: 0\n",
      "episode: 56/367, score: 210.0, e: 0\n",
      "episode: 57/367, score: 195.0, e: 0\n",
      "episode: 58/367, score: 210.0, e: 0\n",
      "episode: 59/367, score: 210.0, e: 0\n",
      "episode: 60/367, score: 202.0, e: 0\n",
      "episode: 61/367, score: 205.0, e: 0\n",
      "episode: 62/367, score: 210.0, e: 0\n",
      "episode: 63/367, score: 210.0, e: 0\n",
      "episode: 64/367, score: 199.0, e: 0\n",
      "episode: 65/367, score: 208.0, e: 0\n",
      "episode: 66/367, score: 210.0, e: 0\n",
      "episode: 67/367, score: 210.0, e: 0\n",
      "episode: 68/367, score: 197.0, e: 0\n",
      "episode: 69/367, score: 206.0, e: 0\n",
      "episode: 70/367, score: 182.0, e: 0\n",
      "episode: 71/367, score: 192.0, e: 0\n",
      "episode: 72/367, score: 210.0, e: 0\n",
      "episode: 73/367, score: 210.0, e: 0\n",
      "episode: 74/367, score: 210.0, e: 0\n",
      "episode: 75/367, score: 191.0, e: 0\n",
      "episode: 76/367, score: 210.0, e: 0\n",
      "episode: 77/367, score: 180.0, e: 0\n",
      "episode: 78/367, score: 194.0, e: 0\n",
      "episode: 79/367, score: 210.0, e: 0\n",
      "episode: 80/367, score: 193.0, e: 0\n",
      "episode: 81/367, score: 210.0, e: 0\n",
      "episode: 82/367, score: 210.0, e: 0\n",
      "episode: 83/367, score: 210.0, e: 0\n",
      "episode: 84/367, score: 210.0, e: 0\n",
      "episode: 85/367, score: 210.0, e: 0\n",
      "episode: 86/367, score: 186.0, e: 0\n",
      "episode: 87/367, score: 202.0, e: 0\n",
      "episode: 88/367, score: 210.0, e: 0\n",
      "episode: 89/367, score: 210.0, e: 0\n",
      "episode: 90/367, score: 189.0, e: 0\n",
      "episode: 91/367, score: 210.0, e: 0\n",
      "episode: 92/367, score: 209.0, e: 0\n",
      "episode: 93/367, score: 210.0, e: 0\n",
      "episode: 94/367, score: 197.0, e: 0\n",
      "episode: 95/367, score: 201.0, e: 0\n",
      "episode: 96/367, score: 183.0, e: 0\n",
      "episode: 97/367, score: 210.0, e: 0\n",
      "episode: 98/367, score: 210.0, e: 0\n",
      "episode: 99/367, score: 210.0, e: 0\n",
      "episode: 100/367, score: 210.0, e: 0\n",
      "episode: 101/367, score: 204.0, e: 0\n",
      "episode: 102/367, score: 174.0, e: 0\n",
      "episode: 103/367, score: 197.0, e: 0\n",
      "episode: 104/367, score: 185.0, e: 0\n",
      "episode: 105/367, score: 197.0, e: 0\n",
      "episode: 106/367, score: 210.0, e: 0\n",
      "episode: 107/367, score: 210.0, e: 0\n",
      "episode: 108/367, score: 206.0, e: 0\n",
      "episode: 109/367, score: 196.0, e: 0\n",
      "episode: 110/367, score: 209.0, e: 0\n",
      "episode: 111/367, score: 210.0, e: 0\n",
      "episode: 112/367, score: 188.0, e: 0\n",
      "episode: 113/367, score: 210.0, e: 0\n",
      "episode: 114/367, score: 210.0, e: 0\n",
      "episode: 115/367, score: 210.0, e: 0\n",
      "episode: 116/367, score: 210.0, e: 0\n",
      "episode: 117/367, score: 199.0, e: 0\n",
      "episode: 118/367, score: 210.0, e: 0\n",
      "episode: 119/367, score: 204.0, e: 0\n",
      "episode: 120/367, score: 193.0, e: 0\n",
      "episode: 121/367, score: 210.0, e: 0\n",
      "episode: 122/367, score: 184.0, e: 0\n",
      "episode: 123/367, score: 200.0, e: 0\n",
      "episode: 124/367, score: 199.0, e: 0\n",
      "episode: 125/367, score: 210.0, e: 0\n",
      "episode: 126/367, score: 191.0, e: 0\n",
      "episode: 127/367, score: 194.0, e: 0\n",
      "episode: 128/367, score: 210.0, e: 0\n",
      "episode: 129/367, score: 189.0, e: 0\n",
      "episode: 130/367, score: 194.0, e: 0\n",
      "episode: 131/367, score: 210.0, e: 0\n",
      "episode: 132/367, score: 203.0, e: 0\n",
      "episode: 133/367, score: 210.0, e: 0\n",
      "episode: 134/367, score: 210.0, e: 0\n",
      "episode: 135/367, score: 210.0, e: 0\n",
      "episode: 136/367, score: 210.0, e: 0\n",
      "episode: 137/367, score: 210.0, e: 0\n",
      "episode: 138/367, score: 210.0, e: 0\n",
      "episode: 139/367, score: 210.0, e: 0\n",
      "episode: 140/367, score: 188.0, e: 0\n",
      "episode: 141/367, score: 210.0, e: 0\n",
      "episode: 142/367, score: 202.0, e: 0\n",
      "episode: 143/367, score: 210.0, e: 0\n",
      "episode: 144/367, score: 210.0, e: 0\n",
      "episode: 145/367, score: 210.0, e: 0\n",
      "episode: 146/367, score: 186.0, e: 0\n",
      "episode: 147/367, score: 210.0, e: 0\n",
      "episode: 148/367, score: 210.0, e: 0\n",
      "episode: 149/367, score: 197.0, e: 0\n",
      "episode: 150/367, score: 210.0, e: 0\n",
      "episode: 151/367, score: 192.0, e: 0\n",
      "episode: 152/367, score: 210.0, e: 0\n",
      "episode: 153/367, score: 210.0, e: 0\n",
      "episode: 154/367, score: 210.0, e: 0\n",
      "episode: 155/367, score: 185.0, e: 0\n",
      "episode: 156/367, score: 210.0, e: 0\n",
      "episode: 157/367, score: 210.0, e: 0\n",
      "episode: 158/367, score: 207.0, e: 0\n",
      "episode: 159/367, score: 192.0, e: 0\n",
      "episode: 160/367, score: 193.0, e: 0\n",
      "episode: 161/367, score: 210.0, e: 0\n",
      "episode: 162/367, score: 210.0, e: 0\n",
      "episode: 163/367, score: 210.0, e: 0\n",
      "episode: 164/367, score: 210.0, e: 0\n",
      "episode: 165/367, score: 210.0, e: 0\n",
      "episode: 166/367, score: 201.0, e: 0\n",
      "episode: 167/367, score: 210.0, e: 0\n",
      "episode: 168/367, score: 210.0, e: 0\n",
      "episode: 169/367, score: 210.0, e: 0\n",
      "episode: 170/367, score: 208.0, e: 0\n",
      "episode: 171/367, score: 210.0, e: 0\n",
      "episode: 172/367, score: 185.0, e: 0\n",
      "episode: 173/367, score: 210.0, e: 0\n",
      "episode: 174/367, score: 188.0, e: 0\n",
      "episode: 175/367, score: 175.0, e: 0\n",
      "episode: 176/367, score: 210.0, e: 0\n",
      "episode: 177/367, score: 210.0, e: 0\n",
      "episode: 178/367, score: 209.0, e: 0\n",
      "episode: 179/367, score: 202.0, e: 0\n",
      "episode: 180/367, score: 197.0, e: 0\n",
      "episode: 181/367, score: 208.0, e: 0\n",
      "episode: 182/367, score: 210.0, e: 0\n",
      "episode: 183/367, score: 198.0, e: 0\n",
      "episode: 184/367, score: 210.0, e: 0\n",
      "episode: 185/367, score: 210.0, e: 0\n",
      "episode: 186/367, score: 199.0, e: 0\n",
      "episode: 187/367, score: 202.0, e: 0\n",
      "episode: 188/367, score: 210.0, e: 0\n",
      "episode: 189/367, score: 194.0, e: 0\n",
      "episode: 190/367, score: 182.0, e: 0\n",
      "episode: 191/367, score: 200.0, e: 0\n",
      "episode: 192/367, score: 210.0, e: 0\n",
      "episode: 193/367, score: 181.0, e: 0\n",
      "episode: 194/367, score: 205.0, e: 0\n",
      "episode: 195/367, score: 210.0, e: 0\n",
      "episode: 196/367, score: 210.0, e: 0\n",
      "episode: 197/367, score: 206.0, e: 0\n",
      "episode: 198/367, score: 200.0, e: 0\n",
      "episode: 199/367, score: 210.0, e: 0\n",
      "episode: 200/367, score: 210.0, e: 0\n",
      "episode: 201/367, score: 210.0, e: 0\n",
      "episode: 202/367, score: 210.0, e: 0\n",
      "episode: 203/367, score: 210.0, e: 0\n",
      "episode: 204/367, score: 210.0, e: 0\n",
      "episode: 205/367, score: 172.0, e: 0\n",
      "episode: 206/367, score: 210.0, e: 0\n",
      "episode: 207/367, score: 188.0, e: 0\n",
      "episode: 208/367, score: 210.0, e: 0\n",
      "episode: 209/367, score: 210.0, e: 0\n",
      "episode: 210/367, score: 210.0, e: 0\n",
      "episode: 211/367, score: 190.0, e: 0\n",
      "episode: 212/367, score: 186.0, e: 0\n",
      "episode: 213/367, score: 210.0, e: 0\n",
      "episode: 214/367, score: 210.0, e: 0\n",
      "episode: 215/367, score: 185.0, e: 0\n",
      "episode: 216/367, score: 210.0, e: 0\n",
      "episode: 217/367, score: 195.0, e: 0\n",
      "episode: 218/367, score: 210.0, e: 0\n",
      "episode: 219/367, score: 199.0, e: 0\n",
      "episode: 220/367, score: 210.0, e: 0\n",
      "episode: 221/367, score: 182.0, e: 0\n",
      "episode: 222/367, score: 210.0, e: 0\n",
      "episode: 223/367, score: 210.0, e: 0\n",
      "episode: 224/367, score: 210.0, e: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 225/367, score: 189.0, e: 0\n",
      "episode: 226/367, score: 210.0, e: 0\n",
      "episode: 227/367, score: 210.0, e: 0\n",
      "episode: 228/367, score: 195.0, e: 0\n",
      "episode: 229/367, score: 210.0, e: 0\n",
      "episode: 230/367, score: 210.0, e: 0\n",
      "episode: 231/367, score: 210.0, e: 0\n",
      "episode: 232/367, score: 181.0, e: 0\n",
      "episode: 233/367, score: 197.0, e: 0\n",
      "episode: 234/367, score: 198.0, e: 0\n",
      "episode: 235/367, score: 182.0, e: 0\n",
      "episode: 236/367, score: 187.0, e: 0\n",
      "episode: 237/367, score: 210.0, e: 0\n",
      "episode: 238/367, score: 210.0, e: 0\n",
      "episode: 239/367, score: 210.0, e: 0\n",
      "episode: 240/367, score: 184.0, e: 0\n",
      "episode: 241/367, score: 179.0, e: 0\n",
      "episode: 242/367, score: 210.0, e: 0\n",
      "episode: 243/367, score: 194.0, e: 0\n",
      "episode: 244/367, score: 203.0, e: 0\n",
      "episode: 245/367, score: 210.0, e: 0\n",
      "episode: 246/367, score: 210.0, e: 0\n",
      "episode: 247/367, score: 210.0, e: 0\n",
      "episode: 248/367, score: 185.0, e: 0\n",
      "episode: 249/367, score: 190.0, e: 0\n",
      "episode: 250/367, score: 210.0, e: 0\n",
      "episode: 251/367, score: 208.0, e: 0\n",
      "episode: 252/367, score: 193.0, e: 0\n",
      "episode: 253/367, score: 191.0, e: 0\n",
      "episode: 254/367, score: 210.0, e: 0\n",
      "episode: 255/367, score: 191.0, e: 0\n",
      "episode: 256/367, score: 197.0, e: 0\n",
      "episode: 257/367, score: 210.0, e: 0\n",
      "episode: 258/367, score: 204.0, e: 0\n",
      "episode: 259/367, score: 206.0, e: 0\n",
      "episode: 260/367, score: 202.0, e: 0\n",
      "episode: 261/367, score: 210.0, e: 0\n",
      "episode: 262/367, score: 210.0, e: 0\n",
      "episode: 263/367, score: 210.0, e: 0\n",
      "episode: 264/367, score: 184.0, e: 0\n",
      "episode: 265/367, score: 210.0, e: 0\n",
      "episode: 266/367, score: 210.0, e: 0\n",
      "episode: 267/367, score: 190.0, e: 0\n",
      "episode: 268/367, score: 210.0, e: 0\n",
      "episode: 269/367, score: 181.0, e: 0\n",
      "episode: 270/367, score: 204.0, e: 0\n",
      "episode: 271/367, score: 210.0, e: 0\n",
      "episode: 272/367, score: 210.0, e: 0\n",
      "episode: 273/367, score: 210.0, e: 0\n",
      "episode: 274/367, score: 210.0, e: 0\n",
      "episode: 275/367, score: 189.0, e: 0\n",
      "episode: 276/367, score: 209.0, e: 0\n",
      "episode: 277/367, score: 191.0, e: 0\n",
      "episode: 278/367, score: 182.0, e: 0\n",
      "episode: 279/367, score: 208.0, e: 0\n",
      "episode: 280/367, score: 210.0, e: 0\n",
      "episode: 281/367, score: 179.0, e: 0\n",
      "episode: 282/367, score: 210.0, e: 0\n",
      "episode: 283/367, score: 210.0, e: 0\n",
      "episode: 284/367, score: 210.0, e: 0\n",
      "episode: 285/367, score: 210.0, e: 0\n",
      "episode: 286/367, score: 207.0, e: 0\n",
      "episode: 287/367, score: 210.0, e: 0\n",
      "episode: 288/367, score: 210.0, e: 0\n",
      "episode: 289/367, score: 200.0, e: 0\n",
      "episode: 290/367, score: 210.0, e: 0\n",
      "episode: 291/367, score: 210.0, e: 0\n",
      "episode: 292/367, score: 210.0, e: 0\n",
      "episode: 293/367, score: 210.0, e: 0\n",
      "episode: 294/367, score: 198.0, e: 0\n",
      "episode: 295/367, score: 202.0, e: 0\n",
      "episode: 296/367, score: 210.0, e: 0\n",
      "episode: 297/367, score: 210.0, e: 0\n",
      "episode: 298/367, score: 210.0, e: 0\n",
      "episode: 299/367, score: 210.0, e: 0\n",
      "episode: 300/367, score: 205.0, e: 0\n",
      "episode: 301/367, score: 210.0, e: 0\n",
      "episode: 302/367, score: 187.0, e: 0\n",
      "episode: 303/367, score: 181.0, e: 0\n",
      "episode: 304/367, score: 210.0, e: 0\n",
      "episode: 305/367, score: 210.0, e: 0\n",
      "episode: 306/367, score: 210.0, e: 0\n",
      "episode: 307/367, score: 210.0, e: 0\n",
      "episode: 308/367, score: 210.0, e: 0\n",
      "episode: 309/367, score: 206.0, e: 0\n",
      "episode: 310/367, score: 203.0, e: 0\n",
      "episode: 311/367, score: 210.0, e: 0\n",
      "episode: 312/367, score: 210.0, e: 0\n",
      "episode: 313/367, score: 210.0, e: 0\n",
      "episode: 314/367, score: 190.0, e: 0\n",
      "episode: 315/367, score: 210.0, e: 0\n",
      "episode: 316/367, score: 200.0, e: 0\n",
      "episode: 317/367, score: 210.0, e: 0\n",
      "episode: 318/367, score: 207.0, e: 0\n",
      "episode: 319/367, score: 210.0, e: 0\n",
      "episode: 320/367, score: 210.0, e: 0\n",
      "episode: 321/367, score: 210.0, e: 0\n",
      "episode: 322/367, score: 210.0, e: 0\n",
      "episode: 323/367, score: 210.0, e: 0\n",
      "episode: 324/367, score: 210.0, e: 0\n",
      "episode: 325/367, score: 210.0, e: 0\n",
      "episode: 326/367, score: 210.0, e: 0\n",
      "episode: 327/367, score: 195.0, e: 0\n",
      "episode: 328/367, score: 202.0, e: 0\n",
      "episode: 329/367, score: 192.0, e: 0\n",
      "episode: 330/367, score: 210.0, e: 0\n",
      "episode: 331/367, score: 210.0, e: 0\n",
      "episode: 332/367, score: 210.0, e: 0\n",
      "episode: 333/367, score: 210.0, e: 0\n",
      "episode: 334/367, score: 210.0, e: 0\n",
      "episode: 335/367, score: 210.0, e: 0\n",
      "episode: 336/367, score: 210.0, e: 0\n",
      "episode: 337/367, score: 210.0, e: 0\n",
      "episode: 338/367, score: 199.0, e: 0\n",
      "episode: 339/367, score: 210.0, e: 0\n",
      "episode: 340/367, score: 210.0, e: 0\n",
      "episode: 341/367, score: 210.0, e: 0\n",
      "episode: 342/367, score: 198.0, e: 0\n",
      "episode: 343/367, score: 210.0, e: 0\n",
      "episode: 344/367, score: 190.0, e: 0\n",
      "episode: 345/367, score: 191.0, e: 0\n",
      "episode: 346/367, score: 210.0, e: 0\n",
      "episode: 347/367, score: 210.0, e: 0\n",
      "episode: 348/367, score: 210.0, e: 0\n",
      "episode: 349/367, score: 191.0, e: 0\n",
      "episode: 350/367, score: 210.0, e: 0\n",
      "episode: 351/367, score: 210.0, e: 0\n",
      "episode: 352/367, score: 210.0, e: 0\n",
      "episode: 353/367, score: 210.0, e: 0\n",
      "episode: 354/367, score: 210.0, e: 0\n",
      "episode: 355/367, score: 206.0, e: 0\n",
      "episode: 356/367, score: 181.0, e: 0\n",
      "episode: 357/367, score: 210.0, e: 0\n",
      "episode: 358/367, score: 210.0, e: 0\n",
      "episode: 359/367, score: 210.0, e: 0\n",
      "episode: 360/367, score: 203.0, e: 0\n",
      "episode: 361/367, score: 210.0, e: 0\n",
      "episode: 362/367, score: 210.0, e: 0\n",
      "episode: 363/367, score: 208.0, e: 0\n",
      "episode: 364/367, score: 190.0, e: 0\n",
      "episode: 365/367, score: 184.0, e: 0\n",
      "episode: 366/367, score: 210.0, e: 0\n"
     ]
    }
   ],
   "source": [
    "#Test the agent that was trained\n",
    "#   In this section we ALWAYS use exploit don't train any more\n",
    "for e_test in range(TEST_Episodes):\n",
    "    state = envCartPole.reset()\n",
    "    state = np.reshape(state, [1, nS])\n",
    "    tot_rewards = 0\n",
    "    for t_test in range(210):\n",
    "        action = dqn.test_action(state)\n",
    "        nstate, reward, done, _ = envCartPole.step(action)\n",
    "        nstate = np.reshape( nstate, [1, nS])\n",
    "        tot_rewards += reward\n",
    "        #DON'T STORE ANYTHING DURING TESTING\n",
    "        state = nstate\n",
    "        #done: CartPole fell. \n",
    "        #t_test == 209: CartPole stayed upright\n",
    "        if done or t_test == 209: \n",
    "            rewards.append(tot_rewards)\n",
    "            epsilons.append(0) #We are doing full exploit\n",
    "            print(\"episode: {}/{}, score: {}, e: {}\"\n",
    "                  .format(e_test, TEST_Episodes, tot_rewards, 0))\n",
    "            break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**  \n",
    "Here is a graph of the results. If everything was done correctly you should see the rewards over the red line.  \n",
    "\n",
    "Black: This is the 100 episode rolling average  \n",
    "Red: This is the \"solved\" line at 195  \n",
    "Blue: This is the reward for each episode  \n",
    "Green: This is the value of epsilon scaled by 200  \n",
    "Yellow: This is where the tests started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd5wcZd3Av89s3yt7PXeXS3LphSSEJBQJVRAJSFNR6UVEiq+IAoLyiviKoihKUyCUEIRQRCkCUgOoQDAJoYQkQPqlXu93e7v7vH/Mzt7s7my7sreB5/v5JHs7OzPPszM7z+/51UdIKVEoFArF5w9tpDugUCgUipFBCQCFQqH4nKIEgEKhUHxOUQJAoVAoPqcoAaBQKBSfU+wj3QGAsrIyWVtbO9Ld+MzS1bUeAK936gj3RKFQDCUrV65skFKWD/T4nBAAtbW1rFixYqS78Znl3XePAGC//V4b0X4oFIqhRQixZTDHKxOQQqFQfE5RAkChUCg+pygBoFAoFJ9TlABQKBSKzylKACgUCsXnFCUAFAqF4nOKEgAKhULxOSUn8gByna2NXWxp6uTQyeW8uGYXGxs6OffgWtwOW8bnCoUki9/cTEuXn2P2qaSnL0iey870qsIh7/dzH+zkwPElBEOSpk4/j6/YxramLjRNsE+1jzU7Wtmn2scHdS34vE4qClzMGVPEqq3NbNjTgRCCr8+rYe3ONtwOG4FQiHW72unxB8l326n0efh0dzuzaooYV+rlH+/twOuyM7rIwye725lRXcg+1T7W72pnY0MHHT0BZtcU8eGOVmZW++gLhmjvDVDkcfDJng7O/sI4Hv3vNsoLXMwdW8xfV9bxpRmjmDnax46Wbh5bsQ2HTWNGdSGVhW66/AHaewK8t62VYCgEwJHTKugNhPjvpiamVRUSDIXo7A3ytXk1rNjcxBsf1wNwyORyDhhfAsCqrc386+MGTjtgDA6bxksf7UYIItdq3zFF5LvsFLjttPcE2L+2hBfX7GLfMUW8X9fKrNE+Ptjeil0TvLu1Oeoe7DPaR2tXHx6njU92tzO1spBtzV3Ulnpp7e6jwO1g3c42Jo8qYEdLN2NKvBw3q4qXPtrNB3UtALidNsaV5LF+Vxu1ZXn0BUOMKnRTU+ylrrmLdbvaOePAsRS4Hby5oYHevhDv1bVw9PRRdPcFyXfZmVZZwJOrt3PMjEoeX7ENr9POEVPLWfrOtsi1c9g0Ztb4EMD7da0AnH7gWF76aDfBkKTY66TQY0cgaOzspbcvRF1zFzOqfXy6p51JFfl8uqeDQEjyzf3HUOXzAPD3d+vYVN/J/NoSqnxumjr9FLgd/PPDnRR6HJx+4FieeW8HX583hs2Nnexu7WGUz83Olh4OmVzG8x/sZO3ONqZUFlDX3M24Ei/tPQFOnFPN4jc309UbwOO0c94C/ZkMBEM8saoOn8fBRzvaIvfhox1tzBzt48PtrUgpmVCez/7jS3h8xTZCIcm40jwAjp2pX6OmTj8ANcXeyLXSBMys8WETgpbuPlq7/NS390bd81E+N2ccOI6VW5p5ff2eqM9smsb0qgI+3N5KSZ6TSp+beeNKeOPjerY0djKjupAN9Z309gUBmDuumIoCd+RaleW72NPew3kLxvPK2t2DHCGUAEiLw25aBsDmG4/nwgdXAjBrtI8Fk8oyPtfGhg5+8Y+PAPhkTwfPf7grcu6hpKXLzyUPrWLfMUWcNrGDli4/N77zfsbnqWvu5olVdUn3Kct3Mb2qgH990hC13RMWGn3B9NacaOnys+hfmwA4aU41T63ewce72/nzmfN4fEUdf3z5k5TnWF3XytbGTjY3dkVtP2JqOb97cT1vb2wC4LWP63n6e4cA8PsX1/OfTxsJScm9/95ER28gaRuf3LCQCx9cyYTyPDbWd1JT7KGuuTvyuRD660CX2lj3f8dy7ZMfsLutN+W+48vy2NTQydqdbfz267M5fdHyyGdrdrTx0kf6IPHohQdx+aPvsX/tVv67WRdS3z5kPPf+e1PS80sJf3j544y/g8OmcemRkwgEQ/zwsfeQkoiAAFg4szLy29/a1MWSt7bQ3NXHjc+vizrP5huP50ePv0eXPxjXxktrd0e+H+i/n2/sP4Zn39/JzS+l7rMm4MLDJnLn6xuitr+wZhcvfhQ9uJ57cC2L39yc8Fyx9/xLM0Zx80v678r4zPy5mWmVBazb1W553spCN/uPL+GZ93ZEbR9T7I3r40BQJqAB4g+GBnRcT1//cX0DPEc6hMI/tI179MHfYNHZ83HaUt/2m74+m3yXnb+9Gz/4//Gbc6LeN3T08uaGRo6ePiqyrcjroLsvmPbgD7BiS//s+anV+g++vUcfjLv8iQdlmybY9OvjOHB8CT19wbgZmXGenr4Qh00p51v7j2FHS3fUZ6BrAubB/7oTZuB1xmt5xv4b6zsBogb/gyeWsunXx7Pp18dzxoFjU39pCz7c3kpnb5BvHzKef111ZGT7l2aMitvXH9B/Q0+t3sGra6Nnm63dfZG/6zv0a7J6W0tk2/JNjTjtGptvPJ5V//sly740m347mWDMYP3BUGTQ6w30D+K72nrijvn7qu1x2xo7ei0HfyAyu7/rrHn66xsbOer3r/P4ym2RfU47YAynHTAm6rjyAhf/+5UZhCRsbuikosDFn86YG/m8rUe/bn86Yy4PXXAgAP/6pD7hd339yiMi99x4Njp6AnT2Bjl0clnks02/Pt7y2TOEopn/XP1Frl44jV1tPdS3x1+rf7y/c8BjkBklAAZIKDSw6V3AdFxwgOdIrx39x9EeM5sdW+LF7Yi+7TZNEEt1kQeHTVjOWEYVuiN/l+Q5Af27nDinOrJ9hoVJy2hmXKmXy46aHPf5u1tb4rYZA3J3n/UgALqmIYTAadfoDYToNA0YxgPX0RugLxjCaRNU+Tw0dPgjA5LRxsot0eYbl91GodsR116baWCNpaLAFXW8mbJ8Z8LjzKzc0kx3XxCPw0ZxXv8x88cVM7kiP2pf4z4DcTNCw4QBRAZRs0D+cHsbPo/+/ax+AxAtRDLBH26n1zThMYQVQH17L1U+/XdkXP/1u+NnwR+GB/mSvPhrt7utByH037SZbU39Atlh05hUURD1uc/joMClGz82N3ZSmu+KOkdpnity7ORR+vXeENb0rDAfa0wYuvxBesL30EyhR2/X/DsJWIwDbrvGlHDba3a0Maqwf3+Pw8bqbS1R13OgKAEwQKxuWjqYZ/0DPUc6BBLMvMeWePHEzGqLvfEPV6XPjSOBpmA8uKCrqAYTy/Mif+9THS8AjIfY47DhtKf+6VUUuPh4dztPrd5OT1+QYm/8YAxEfDEuu0ZzZ/SM1WizozeAPxDCYdOoKtL7vLtVnxV3RLSMaCHjsmuRB9aMMUO0otwsAGIErWETjyVWy1i3q51gSOJx2sgzfVbsdfLA+QdE7RsISqrD9yN2JrnVZAbrNn23Arc9cl2KwgLAYYsWAA6bwGETSYWd1XFCQJ7TFvmdG7NUmyaiBqw97b2MLtKvR1t3Yu3u8kdXA9G/OYNASFKW7yLfldiSbdc0jptVSZXPHRlQizwO8t36MVsauyjLdzK21Bt/rE1Qnu+K/O7GFMfvc84XxiFMNh6vUz9vRADE3FtjQlFdFP9bMIQx6L/pKaN0wdXeE6DS9NuZWJFHT19wSASA8gEMkIFqAGYBEBrG9ZgTCQCP0xY3KynNc9LQEW02qfZ5Eg7S5llplc/NRzv1WZpZM9in2hd3XJHXSUOHH7fDhj3BjNNMTbGHVVtbuOyR1Rw/qwqfx0FzV/yA5HHq/XTaNXa2dkd9VprvZFdbD529Afz+PgKdLbj7PAS7Wtne0sXYUi8dvQFK8pxRM2bQB3BrDSDxgFVR0H8NXDHXr9Ln5oPtrXHH+DyOiPDRBJF74Q5rNgbFec64e9IXDFFblseO1p44AWA2EXSaTGhjS7x4nTaaOv0JNQCX3Yag39yViHyXPeqeeB02HHYt8js3NIB8lz1K+/AHQtQUe1ixpZn2JALVuCdVPjdrwtqAmWqfO07QmnHYdY3vrWuO4udPr+Hj3R26BhAWAN19QUrynFH32dCanTYNIQTTKgt5a2MjlT43TpsWua6za3xcf9LMqPa8LkMDCNDdF8QdowUWhK93mStA96ZVyIAfzZWHo6QGl4SuDZ9AKMjtt6xh1cqV7HrzQzRXHivy3TS3dyNDQfq8Nppa22kaOyHh904XJQAGSHCAg7cxMNs1kXCQHgr6QtGzA5smOGW/0QBx0UvFefGDnMdpS+grMM9KR5lmZuYZTE2xJxI1Y1AS1jS8Thv2BOfed0wR74Xt1GNKvKwKm4Vau/vwOO047VrczMcT0QBs9AUlUobo3baGYGczG1dtZcfqtzltSYDm1jbe6GrjnvBx5yybwxmnnsLud+qp9EraWnrQ8oog2IcMBnjJ/RF1m5rpqO9COFzIvh6E08u/Xu+ie8sn2H2jsPtGRQ3S5msQawIabTHrA31WuLNVt/MWeZ00dvijvpdBsdcBoQB9TduxF1UiNBuBkKS6yMOKzU1JzWRmDaCy0E2eyw40U+R1IKVk66ZNdLz/InZfJY7SMdiELiRbCpIPEQVuXSiH+nohFKCnYSc9HQ3sKNwPKfeJmNkK3Hb2xDi1a8Iz6jYLIWPTRJSJNJH2VOXzJI3GM/+GC8P3psBtj9IaDJPP8bOrePb9nXSGBYChAe83toi3NjaS77LjsmtJbe+yr5tQb1dYAwjhdmh8/PHHLF++nKVLl/Lvdz+iVzh5sLkOf0/0ZMXsbbv67zBhwgQ0XATa6unqtRMMAJoNZ14+2Jxsfuv5hP1IFyUABshA7ffGzMjtsGVVAxhXksd3DtMdVLEmB7N9dVypl5mj9dl7Ig3APHhXmWb9ZpORz+OgptjL2p39szazCSjWdGBwxJTyiAAwq8mt3X24HRpWioPHaScUCrH749U0vfIkXZ+8TbBVt4c3O1zYq6YwcWota7c1sv/Bh3DsrBr+74nl9Ox+l59fdx0ATRZ9ufVFyy7yk6f6/xYON46yMWieQjS7i9++6eX3vW10dnayp7md1pALe2E5CMEzbxdQv6sdMH0JIQiGtQ8Z6KWpt40tvgoCeeU8uDGf511B6t/ZiHC6ufj1Hj5cvYqenh6w2XGU1OCpmsxDd6+lec8OhN0JMoTm8SEcToIdTchgHzaPjz/9czINoXzsBeW8sypIy5a11PfAsvJi9r+tk5UrV0Z9R2MwWiM00DR9llo2DmQIGexD2BwgBDub6ghKCPa0o49QOhsfhb/9opgvHH40Hf7RtJXk09wewFk5CZvXh+b0UOLoI9jVSlt3/OAe+3xVWpiAQNfwYjUtM3at/zPD3KVpggK3LviMcwDccfpcXlzzbMQk6LAJWlpa8AWa6WvYxvLX1tO2cQudAUHI38X69/r4n/WP8sknn7Bx40Z6e3upq6sjFApx4u0OtMJyttokv6jfCcCYMWPwVU+iobmNA750ImudU9HcBci+bvqatjN5VAFbtSpsdgf/veHrVFVVse/1L9La3ccXp1Xw6jrdyX/Fl6dy0wvrqezZyvJbLkn43dMhpQAQQowBlgCVQAi4W0p5ixCiBHgUqAU2A9+QUjYLfTp0C3Ac0AWcK6VcNahe5iADFwD6cS67NqxO4NgII/PAmcwH8KNjpnLivrozN5EPwEyiB9PndTC6yBMlAIrCtlS30xb1YJo5cloFt7yih3uaZ9NtPX2WM2gpQ7RteJcFC67g7bffBpsdT+1+5B16BvbSsXz3pMNZvHw75x03jdtf/ZQFc2u45Nhp3LZrAtcsvJ6Dqu0c/8fXOPewqTzwn42Eejr0wU2zceeZc7n/P5tYvqGekL8H4XARbNvDN+eN5pHlm+lr3kGgeQf++i2EutoIBnrpdvqoqa6ipqYGX2eIlWs+oa9RH053+130maJfjAGo3WXH3xtAaDYKyipo2raeQMebvLm+gJIiH33tIUJ93cgp47noootYsqaHvpZd+HdvoOOT5UyaPhPXlAV09fh1gdLZjAwGsI2fi7C7CHY00tXZQM+ujwl2NNPhcDBpnznUd3XS1rCb8soibrrpJm790EZvZxv+hq2U+bw43Hk07NhGb5+fQGu9LlTtDjSnl2BHIzIUYszsBexuasVeUIbmzqegooaKMRPwdW5jXGAbf33ib7S3tdIYc99s+SV853ethIJB9hRXEQJkKIRr9DSETRdk00bls3ZHM6HeTu5c5qWh046zYjzC4UZz5eEeO5ueZhcvv7CV1jcfpa+pDkd5La6qKYS623FWTWbPFsm//72btrY2/vXqf2l89R2eeL6JZ65tYtumLchQkKv+5OWKgB+/308oJKmfNJeAp4SvPHQxO+r6I4p2xHyHZmBnQQGTJ09mzpw5eL1eSioquX/5TvJkN817djCuIp8bfn4tX/jCF5g9ezan3fMO72xq4offmsNlj6yOnMszfi4Hzalm9+od2DRBVVUV0P8MOmyCK788lTU7WiMaj6iID6TIlHQ0gADwIynlKiFEAbBSCPEScC7wipTyRiHE1cDVwI+BhcDk8L8DgT+HXz9TDIUGMBwCQErJ/f/ZHDcwm80UsQN7qUkDcJpm5uk4ahOp5roGEP2ZIXg8Dhv2GA3g7C+M45PdHcw0OY/zTGp6a3cfE8vzEabZc9eG/9L25qNs3bGOUaNGcdL3rmeVfTqayxux6ZcX6Y6/P778CV3+IE67FtE++oIh3AUl2AvKmFQzCpu3EZu333dRU1NDXkkX9ob+6+AoqqR86ng89aV4mBf1HV68/LCI4w7gryvruOLx9wA4dp9Kvji9gqv+Gp+L8dW5o/lbOATyqGkVvBKe6T1w/gEcPqWc2qufBeDtGxZit2n8Pfze4JKjp/DS2l18uL0tYjoRIjrmfMGkUv7zaSMyGOAb88dy5IxKLnloFUdPH8U958wH4N7//SdaXxDPxPlMGFWATRN07Wwj3vXZzxenV/CyKfy0wG2nuNDNpIr9+POZ8zjnil9y+i3PcWBtEW+t20bv9rVIvy7AzjhiNo+9V49/zyYIBZFIerd9BDIEmsbmBhf5dhvS4aW3S9L96Xo61yyLav/m8D8AW35p3Oe/Cv8z0Fx55NXUMn/ObHYXzUDY7Bw9uYiJlcU4nU7ueW09TR/+i7721Rxw9DF89zsXMHbsWNxuNxUVFfzw+Z3s3lOPLb+EOVPG8sz3D496trr9Qf72s38CUA5cvHAa3z18Ytx1K/TEm12NiZj5yTC0GyOvAuDh5VsBaO9NbPJLl5QCQEq5E9gZ/rtdCLEWGA2cBBwR3u0B4DV0AXASsETq05u3hRBFQoiq8Hks2dSyie6+bjwO68EkV5CmJ2qgg7cRtudyaAP2IyRjc2MXv/jHR3FOPZHE52r+MZqFQyIzjZlEGoDLbosXAI5+ARB77pP3G83cscVR2wpiBIDHYaOvq4X2D/9Fz5b36Vr/b2z5Jex/xpW8eufP+NO/61j9mp7U4w4/OMZsyXCyOmwicm38QUlHr+6AtIrKcNm1qHtucE+C5KlYm73ZNHHnWfN4anV8nDtEazo+U6STcb6bv7Evf393e0K/id0mGFvi5cPtbYwqcLGjtYdCtyMqhNPwMQibHbfLERGu5vwKu01A+BAhiAsXtsIqAsdh63cCS5sdR3EVo2urcbV6cFVNiex34/9+iRf+76WE5/7lyTM586BxADz57nYuW7oS2ddLqK+HQMtu/Ls+5vApZfzwtIWc/vg2bF4ffS27CDRtR9gc+Bu28M1D9+GrX5hGfn4+H7S5uOHVHXxtXg2/P3Vfxl/zHAC3Xf3FyP1fduOr5B12HsGQ5N4rjmB8WV5Un1xvv4zLVgSAZrNHDf4Qf81ite3IeSwmVz4LoWBMwsy+DKONVAmL6ZCRD0AIUQvsBywHRhmDupRypxCiIrzbaGCb6bC68LYoASCEuBC4EIAqaO1tzXkBYB7zBzp49wX049x227A4gY0omFgBlWwoN8/0owVA5iag33xtFsvW6UkziQSA3SbiTEBWCVdmDaCvdQ8r//40G5+8X7dr5xVTMP8kig8/h8nTqsjPz498D5ddizyYsQ+kIxzZ4QwPUh3hWVRpvotYktmWrYh92GOPT3Q+84NvFnrG9frq3Bq+OrcmYbsOm6A6rInlu+3QGi+8600OWKddY/64YmbX+Lh64TTTeaL7l06pkwKLKCmHXYvkARgOeytBkWhwNDAf47BpCM2GcHnRXF7s+SW4a6ZzzLHTOPTQidie1bUiR1EljqJKvf/jZnPIl2fypQN1ITK1089fP2rnkiMmRg3c5hBTs2k21QTouhNmxG2LEwj21NfQoMgizNlp69cADGInGoMhbQEghMgHngB+IKVsi/2i5l0ttsWNdFLKu4G7AUS1kO297VTmV6bbnRHB7LQdcBhoyDABaUMiwQ2Wrd9DICgjcfD5LnvU+c33K/YGmQdj8w8tnQEw9sH+5v5j+eb+egbsvHElVBa6I1mfEdslIu7hynP2n+fMg8YyoSwfAQTaG2h5/QE6P3qd7TJE/vRDKDjoGzgr+kPgDLOQ0x7/sMRG4vTvI+gLhCIOPyMsMHbfaxZOp6XrfZq7/FEZv1bECrFYE1oik5o5BNFjug6pBkgDu6ZFQnM7wwJtRrWP3r4gc8cV8+fXNkQlBDrtGnkue6QUhkF8KGjq+2953WyC3r4gt77ySSTXpdByv+TnN08AEl27VGZKh+m3XZLn5MXLD4/bx/xsmM+XrH+3nrYf88aVJG0bdH+XmZ99ZQY//fsHzBlTFLevpQAwfq/2/j7GnnMwpCUAhBAO9MH/ISnl38KbdxumHSFEFWAYAusAc+51DfH+kzg6/PHp0LmGeVY94ESw8IzIZbcNOMvSivPu/y8Alx6p2xvjBUD8MZcfPYVl6/dwxNTyyDbzwGylAZhT5g1OmlPNF6dVxG0vL3Dx5KULOOjXr8T1IVYDMA92vzx5lt7WE6+ya8mPCPV0UDj/JC747sU8uzkQVU4DQIbnF8YDax7HYgexyIzKrvHCR3phP7CeobrsNmZUe3nmfw7hhNv+HSUAvja3Jq5GUuxsL0742KwfXLMGYA6xTVcAOGwCt0MXALNG+ygvcPGzr0xnUkUBL1vUi0k0sDm0WHOGdft3njmPi/6iRw3lWwzsDpvGmxsaWb6pKSJUrK6vpgk9HDokyXPaojK4AfJc/e0nGuhTCSnzwBnLxUdMZFRBtObnSqANx+JOUzuMna3PHO3jqbDgvWbhNH5tqn1U5NHvoXlksZrUZKJVpCKdKCAB3AuslVLebProaeAc4Mbw61Om7d8TQjyC7vxtTWb/N2j3WxdDyiWCQ1DGwRAcbsfwRAFtCWd/dsbUzjE7T41W96ku5LKjJ9Njih83/9BiH7ofHzuN42bp0Qk3fX12JEb/lm/tl7A/VnZkiYxzAps1AIDXXnuNa84/BbBTefbvcZbXUlUzFjZvTNiW8fCaZ7Iuu8ZPjpvGr55bF/Wd7JrGtqbuSNkAq4HMnGAU29/YrGSPw4YWO4N2JNYAzI5fswAwD/rpqvp2m8Zxs6p49oMdXHPctEhVS7A2rSVKnLLZ0hMA5j4WJPABRPZ12OjoDVheX9CvScAfpDjPSac/WsMyR6clMsek1ACSDOI/PnZa3LYoc2iSc7vSvDfJ/CjfPXwi21u6WfLWFsDaMWwIa7PQTndikA7CyskVtYMQhwD/Aj5ADwMF+Am6H+AxYCywFThVStkUFhi3A8eih4GeJ6VckbSNaiH/8YWZHN9YOpjvMmy8vVEPYptfW8KKzXrE+NhSb8TumgnbW7rZ1tRFSZ6TTn8wUjTroAmD++5GH80OOIPeazaS57Izf4k+UK/b1U5Ll5+plQUUe51IqRcGA5hVUxSZhW6o74gqrDauNM8yJT8ZISl5Z1NT5PgtjZ1U+twUe51RIaIHTihFoDvat9XVsWnTJjweDxOnzuCTBt2ENKbEy/bm7rj8iUKPgxlVhexp72VjfUfEzu8PBJlWVUiRxxG5PuPL8xlV4GLV1uaohLIDJ5Syq7WHYEhS16wL0QPGl6CF1ZY1O9qiMlaNUswGdptuVzfT6Q/wQbis8kETSunoDfDh9v73Rp9mVPv4aEdrpH+b6nVteP/xJdgsVDfjOIMJ5flRtWXMtPcGWBOTfZzoPr67rSXye/Q69WSpPRaFyKZXFUbuXaTCZzjsyKYJCt2OuCJyE8vz2VAfreUfNKGUFVuaCQRD5LnskQQsg/m1JZGM8faeAGt2xGdRT6rIpyzfFXdNDKaMKrCsI5SItTvbIpq5+f4brNzaTF8gxIzqQssscYi+P/tU+yzNZAZbGrvY2dqNEIJZo328X9cCQnBQuFT52l3ttHb5GV3kYUy45lCXP6jvB3xh24crpZTz0/6CMaQTBfRvEvsQj7LYXwKXZtqRdtvgQ5qGG/O4M9AAHuM4TQjLCJPBkqjCaFJ3lulD8yQ21s+TRvWG+FMn8BWZt5cXuOjq7GTnzp3sqa/H7/dTVlbG1KlT8YcE0BNuP3kHjP4Jq+8THqC0yNv+nTRN14+MQdEY2KP8JjFNx14Lq77Fbkt0Lcwaiy2q7+ld8GT3xUqApHlarFI1fF5n1Gze6LtdE/g8TkYVutnVGu8rSVRszthqFeFkPiZRn1Ndo3S/a//+wvLvTNqtLctjc9i0mOqZMa6xJqz37f/5mn6vA3gOE5FSA8gGolrIRf9YxAVzLxjprlhixGG/85OjOOBXuj37imOm8L0vZp6IcfOL67lt2ad8Y94YXvt4T6Tm+2DXA6g1xYZPLM9jQ7hUMcDVB1zN7JoiDj7gXwCcd/87LFtfz33nzueL00ZFHf/6lUdETAjX/O0Dlr6zNXKeG06ZyRnhiIqB9O3a46fzy2fXcv6C8ezjbeP8a29Gc3q45vh9+NWvfkVrayuHHXYYV1xxBV/5ylcQQrChvoOjfv96pP1f/mNtXMmDQyaV8ZcLDuS5D3ZyyUOrIglj21u6efLSBcwZU8SUnz6PPxji1tP248R9qzn65tcjtXNGFbpY/pOj4/prvifn3v8Or63vLwl8/Yn7cN3TayLvJ1fk89IPox2M2wIG5ZMAACAASURBVJq6OPS3/WtJmL/L5huPj7Sz7IojOPJ3rwF6ue7vLFkR177V9TS4/fT9+Mrsast9zX0w+M3XZkUc9WYO++0ytjbpwm9aZQGHTy3nrtc3RpXf2PTr4wAiIZSPXngQ37z7bYq9Dt792TEAXPbIu5Fy3gYPXXAgZ9yzPOr9gkllHPKbV6lr7uaEfavjat6bv/+6XW0c+8d/xfX5/nP358hpFXHXxGDJ+Qdw2JRyy8+suPgvK3n+w13YNcGnvzou7vMDbniZPe29/PMHhzKtMvEiTkf+7jU2NXTy8g8Pi6tGauaOZZ9y0wvrKfI6eOEHh3Hgr16JavuCB/7Ly2v3cNWxU7nkCD0PYE9bT2Qc2vKbrwyvBpAt2ntz3wcQXcp5YOfwByUOTUPTxIDPkYqyfFeUAIBoDeD6E2fifn4tB0+MX9AmUaz5UHDq/DEs39TE8eNtnHDsqbRt3w5IfvwGzJkzh6eeeoqxY6MHJmeS8Ld8l53Dp5RzxZenRu1rriNj+AU0DQj2J7rZo/wEqW2qvzhxJqfe9WZEYMdOAK3yIeJ8AAmurdnubNiM0ymWZ5AoqxqwNFOk833N+zlt/QIgdlacyAlsRhPRdusfHzstspiS8d1TOVUTXbuUTuAMf88uC6erFakcscZ5Uq2HYe6/9TnDEW5mJ3C2o4Cywd7nBB7Y6B0IhsJx8CKjczyxsg6HXYuUaUiGlc3T/OCOLfXy5zPnxe0Dsc62odEOv3/UZGaP9uHzOPjFl0Yzd+5cOjq7ws7d8fz3qoMpKytDsxjIzA+IN8ZR7PM4uMMUlWQMuGYBYDgyDVNIJLEmwxj/saVeFp09nxNv/w/QvwiMsRqYuRJqf99jooJiBMJ9585n1ZaWqId71mgfX95nFNcsnJ5235LFq5sjaQzS/e7pJIIVuHQBkyzT3GnXor6jub/GdrfDxn5jiyzXhEjW51TfxZkkCijZ+RJdU+Nrpmr39tP348+vbYxbvyEWVyQ0uv/3YX7qjPZGLAooGwgh9j4NYKCJYEG9Jn1stcNQSMZFkZj5UbikQCoB4LCJqPhpg3RtoemsFpYpP/xSf/bnj370I1pbW3n8uVe59J+6s6yiIj6ENNIf04NW5HXwyIUHccY9y+noDcQNbmYNwPi+xkzasCf311bpP69MU9CZjzn34Fp2t/UwqtDN3W9sjFqwwyAuESwmDPSL00bxxWmjosKBi7xO7jorM40+mdZm9Vmiexx7HYyBJlnRQrfT6vyx+QTR6z9Y5Zq4HRp/OmMuNzy7lmKvk4Uzo3OCEmsAyQfDZNpRsvMlGuCNaLpUz9OkigJ+/419U7Zn5BPNqC7EZdc4b0Ft1DOuWQiAdDL002X49P0MsGm2vUIDCJhsNgM13/SFZKQcQTCFQFm3q42fP73GMunsryvr+OvKOp5YWcfjK/oTrzUhLEP/0v3JRA2MQ+weevLJJ3nkkUe47LLL2GfmrLSOMT+IPo+DfccU8cuT9RrsnhiNoD/EU0ScdMZ3MARAf2Zl5g+RuS/VRR5u+dZ+EdNIpUVEWFwOwgBj2VMRG7+finQ1gLJwZFGiJRmhX7Myd8GmxX9v8wBuDqk1JlVFXidVPg+3nz6X/zt5JgfHrLdt7rN5QjGYMFArrOLuzSw+f3/O/sI4RhVkFg2XiCOmlnPynGruOH0uQgiuO2Ef9jOVRDEEjvn3msw5nSk5oQHYhG2vSAQLDJEJyNAA+kzn+9lTa/jVKTOjbu7Ff1nFpoZOvn3I+LjzGEXGYrFpwjJOON2IEqsffqTAWNpiJJ5t27Zx2mmnMX/+fK666io60zyXeeAwMiWNPubFfE9jtqcJwb3nzOeh5Vsj5SgiGoDFA56uoLOahV5yxEQ6egN83aJUQ+yDmtCMMUitK1O/TToCwKaJyApaySjJc3L+gvF8fV7/94/VGFx2LaEGsDucJT7OYkWuRH3+/lGTI4u+G8LzkQsP4rX19XELvGdqAkrlA5hWWcgvYhaBGQzjSvP4Y5I8mkQmp9gJ5EDJCQGgCW2v0ACCQ+AE7gvqSVCaEFEhm0vf2cq1x0+PTn83rWebLpoQeB0DNwFZzYx/dMwUtjR0RRaUGQjXXnstUkoef/xxiouL8VssCm6FeXAzEqaMPsZqOoYWZbcJJo8q4Ocn7hP5zBCA/dnCiS/IHafPtVylymrgrCh087tTE6v6lx89hQWT9ByPRKGQyUx/6RCbpJaKVBpHaZ6T20+fS3VR6lmuEIKfxdTEiQ1F1iuwWpswGsKL34wriS66FkuiAdmwmx80oZSDJpTGCYBMTUDGPU50r0aK2P6U5TsjAQmDIScEgE3Y9gofwFAs52j4AOxa/ILrsWYgw8adal1WMwLr7M90f85W6mVpnjMSgjYQbrnlFh588EGuuuoqxo3Tw0gziXIxMKKAjMEg1ils3BMrJ1nEBGSPd7TFcvzsKsvtA5mpX3b04Gu2p8IxwEEuEb88eWZcFcxMMCZKPo9ekbTE60yoARjELuweS6LfS6p7kiyb1wpj0ZihrNM1GBLNU0rzXJ8dAaBpGt2B5IW2coHoWkADUwH6gqFIGGjcZzFLHRraQGxWZTKEsE4VH4jdcCh8AOvWrePyyy/n6KOP5tprr41sH0i4qfEd+gVA9Pfct6aI8xbUWprMYp3A5vyXdG3wmQ4mVly9cFpcxvBgGWoNwHxv/vjNOQhB1OIlqTBCHws9dlq7+6gp9sREAcW377MohGYm0e83VUmGTP0jVeEcksaOwQ+uQ4Fhdo19Fo1VzAZLbggAodHV15V6xxFmKPIAAkGJwy4sZzSxMcP5EQGQvgZg00TS1PNMMKJCBmP7v+GGG/B4PDz00EPk5/fblAcTydBvAor+njZNd6JZEatCGw+Uz+Ng0dnpRd04EwieTLjIYnEQ0KtEGktxpuLp7y3gjY/r+d2Luh0802uZqCidcZ/Nv82Tw2Y/h01LuwCiMTkyrldFoTtGA+g//4PfPiCSNTsQUmoAGU40jGzwYVysLzPClyq2OwMpQ2OFEgAZEBu2ORD8wRB2TbO0McbaTgeiAWhCWBaVGgiDtYd++umnPPzww1x++eWUl0dnY2b6YEYdG+6XVYx7Ioxic4aZyHi99vjpTChP7ewE/XpcccwUjp4xKpPupsX5FlpLImbXFDG7pigiAGKjbmIxKm4aJCoGF9nfQqAYRQDTwVjnorVbN6OU5TujfkPme3/o5HIOnZxepu51J8xgdk10GeVUwi9TrS3RCncjhfHtYis2/OS46XicNq4f5PlzQwCwdwgA8wA90HLQgaAeBmrlhPTHCABjJmbU+IfU+QJCWK8sNBCuPGYabruNE9JIPrPi17/+NU6nkyuuuCLus4H4AAwMm3cmVRHvOmsej63YxoSwbdsQAJkmhA2k/Mdwk+paFnmdNHT06hm9YR9UMgbrADWeE+Max4bIZuqYNThvQbyQTGXazPR3VppB4bhskOj7+bwOfn7iPp8RAbA3agCDcAI77ZrlDzN2hTBDIJhNQP5gCLeWeOATQkQcWYPF53Vw7VfiVz1Kh82bN7NkyRIuvvhiKivjF/rJxCfxx2/OibJ5GjXeY0tIJ2NMiZcfHTM18t64lemWRchlUg3oj1x4EC9+tIuH3t7K9pZuywJxmZwP9Czm2HUZDAyh+pPjpvPJnvZIUpfhFM40NDMTnvneIazc0sTPn/kIyFzTHGxE1lDjNTLZh6lfOSMAuvty3wkc7QMY6IpgEq8tgRM4RgMwkoyaTBpAT18w6VJ9NiGGTAMYDL/97W/RNI2rrrpq0Oc6OSb81HioB1UX3RAAaZQ7yHVSOYEnVeQzqWISC2dW8cKaXSkdrukMNkYRQSuuP3EfakvzOGW/0VHnqvK5ae3uG5JEpqcuXcCaHW1x22fV+JhV44sIgIEMnLeetl/ceg8jxU+Om05pvpNj9xme1RJzRgD0BnsJhoLYksxuRxrzDH3AC8IEQzht1k7gWBOQIRDMAqA3EEratiasF5ZIxSMXHhRV+38wNDY2snjxYs4880xqahKvZTtQxpfmcdlRkznKYhWydDE0ONcwFr/LFumGgY4vy0vohIZ+p3+mYaWxlOa7IgX6zEyqyGfdrvbIMpyDYd8xRexrsaziUJBOva1s4fM6uMpi4ZqhImcEAEB3oJt8Z3oOuZHAHPo5YA0g7AROJwzUiAoy5wH09oWiFjKJRQgxIAfrYBekMXPXXXfR3d3N5ZdfPmTnNKNpgstN5QAGwkB9ALlIpmGgqRguc8MNJ89iQnk+B08c/oWfXvjBYaza2jzs7eztpLMk5H3AV4A9UsqZ4W2PAoaILwJapJRzhBC1wFpgffizt6WUF6XRBgBdfV05LQBS1e5Jh0BIYrMJSztsrGPZ0ADMxcJ6A8GkAiCT1Y+GA7/fz+23384xxxzDzJlDlzI/1BiXeijrqowUQyUArOrODCU+ryOqjs9wMrWygKmVievwK3TS0QAWoy/xuMTYIKX8pvG3EOL3gHmttg1SyjmZdCKiAeS4H2AofAChkMQm0jMBGQN9i0kA9PSF6A1aF+c6Ymo5v/5qekXWhotHH32UnTt3ct99941oP1Jh3L0c8/kNiMGabGIZzjUhFLlFOktCvhGe2ccRXv/3G8AXB9MJm9Dt/rkeCTQUPoCQ1FXsdExAhkAwt5VMA/jOoRNGNI5ZSsnNN9/MjBkz+PKXv5xy/z+fMZea4uQlAIYLI656b9YAvE4bXf7gkEeufBaEoiI9BusDOBTYLaX8xLRtvBDiXaANuFZKGb+OGyCEuBC4EKB8jJ4IkusCwFwBdKBhoMGQRAjr+OTYTGCr9X1buvr4+p1vWZ7bbPt/9MKD9JBRh43OHYmXrhtKXnvtNVavXs2iRYvSGlgXZpBcNNQYprLBlmIeSZ77/qGs3KLs3IqBM1gBcBqw1PR+JzBWStkohJgHPCmE2EdKGRevJaW8G7gbYMqsKbKe+pwXAENiApK6CSidMNC+QHwbGxsSl802224PNDl1320e/pA2KSU33XQTZWVlnHHGGcPe3mC5+RtzePb9HUzbi+3EtWV51A6iaJtCMeDpjxDCDnwVeNTYJqXslVI2hv9eCWwAUnp9DB9ArguA6GJwA9cAbJq1EzhOAFhoAMlqEA2mvMJg+eMf/8jzzz/PlVdeiceTW+n0VpTkOTnrC7V7tQloqDFWNVM+gM8Pg9EAjgbWSSnrjA1CiHKgSUoZFEJMACYDG1OdyBwGmsuYTTQDrQUUknopB+taQNHn7LWw9VvVqTcYqZDGlpYWfvGLX3Dcccdx5ZVXjkgfFIPnz2fOY9m6PYwuyn0BrhgaUo4YQoilwFvAVCFEnRDi2+GPvkW0+QfgMOB9IcR7wF+Bi6SUTSk7sddoAKY8gBQ+gO0t3dRe/Swrt0R//WA4CiidYnB9wVDcqlfJCsMNpr7OYLjllltoaWnhhhtuUDPqvZiyfBenzh8z0t1QZJF0ooBOS7D9XIttTwBPZNqJvUUAGGYfIVL7AP7zaQMADy/fxrxxJZHtRhSQtRM4XgD4PA46TWuyvrx2T8I2R8IE1NLSwh/+8AdOOeUU5szJKPpXoVCMMDlh7Ntr8gCC/anyqQRApIxrTCXvUDgKyOwEPnyKHgUVHwUk8Xn7E7v2HVMUVa7hoQsOjEqsyWZES319PUuXLuXSSy+ltbWV6667LmttKxSKoSEnBIBhNugLpb/wyUhgaAAOW+oFmSOmEItlH20i2gl8xoFjAYticMEQPk+/kjZtVHTESkWBi7MOGhd5X17gSu+LDJKWlhYWLFjA6aefzsMPP8xPf/pT9t038bq4CoUiN8mNWkBhOdQbyI1l2BJh+ADstkw0gNhzhKOAYhbIECJaAEgp8QdCFHn6NYDYlb4cNo3iPCd//OYcDplclhX7eyAQ4LTTTmPz5s08/fTTzJ07l9GjB75YvEKhGDlyQgAYA5c/mP7KVyNBlAaQwgkcUQBi9rOKAhJCH8z9FgvOFOf1x/DnxwgAowZMbLnk4eKdd97hsMMOo7e3l7vvvpsTTjghK+0qFIrhIScEAIBds+e+AAjb6O2aljIMNNFk3CoKyKYJnDYtKvHL0AbMpRKMNYINBrqy0kC59tpr6e3tZcmSJZx11llZbVuhUAw9OeEDAHDanDkrAIzB3JiV220iZSKYUVkxdq+QJE4D0ITAYRNR5aYNYeAxLf5S6O7XBn5+wgwqwwtYZ4O33nqLl156iZtuukkN/grFZ4ScEgC9wdz0ARhDteEDcNjS1wDMFiDjGE0Q5QQWQvcrmH0AhjnIvKi12Qdw7Mzs1tG5/vrrKSsr4+KLL85quwqFYvjIKQGQuxqAPlhHwkDT8AEYmPcyjokzAQndBOQ3mYAMAeC0CQ6aoOcRFJg0gGxm/S5fvpwXXniBK664grw8VXtGofiskDM+AJfNlbsCIPwaMQGlkwcQFhqGE3hzQydH/O41wMIEpOkmILMG0B1O/nI7bNxzzv6s3toSFeaZTQFw/fXXU1payqWXXpq1NhUKxfCjNIA0MKw1wQzyAAyMvd7f3r9mTmwYqBaOAjL7AAwB4HXayXfZOWRyGW7TAubDtWpTLH//+995/vnnueqqq8jPz93V2hQKReYoAZAGhkO3XwBoaTiBw1jsZhMiKmtXEwKP08aWxq6In6DLry+cbXYCu+z9fzuzUPahoaGBSy65hDlz5gzb+r4KhWLkyCkBkKtOYCJRQPoM3aYJy4E96pBIInD8jpomokw4mhCceeA41uxo4+W1uwHo6tM1AI+pGJxZAxjupK9QKMTChQtpbm7mvvvuw+EY/jUFFApFdskZAeCy70U+AJtIuSJYJAw0vJs5IUwT0XV7bJrg2FmVAGxu7ASgJ2ICMguA6Mqgw8mLL77IihUruPPOO9lvv/2y1q5CocgeOSMActoEFOMDsGkaqVwAVmGgBrYYDUAIKHDZcTs09rTpWlCXhQDIhtnH4K677qK8vJzTTz89a20qFIrsogRABvRnAqejAehYmoDCYZ/m90IIKgrc7Gnvpa2nz9IENNSLfydi+/btPPPMM5x//vk4nc7UBygUir2SdBaEuU8IsUcI8aFp28+FENuFEKvD/44zfXaNEOJTIcR6IcSX0+1ILgsAzcgDMPkAUqUBpNIAzMvuGRFBFQUuVm9rYfbPX+TO1zYAehRQtvnVr34FwIUXXpj1thUKRfZIRwNYDBxrsf0PUso54X/PAQghZqCvFLZP+Jg/CSHSMly7bK6crQYanweQWgMgphSEeffY9YCNiX1FoYutTfqiONtb9LURPFm0+wO89NJL3HnnnVx00UVMmDAhq20rFIrsklIASCnfAFIu6xjmJOCR8OLwm4BPgQPSOTCXNQCDfh9AGiagJBpArCnHiOipKIiu7eO0a5ZLRw4n11xzDZMmTeI3v/lNVttVKBTZZzA+gO8JId4Pm4iKw9tGA9tM+9SFt6UklwVAZMGaoFkApDgm8pcM/x8dBWTG0AhiF3TxOrM7+1+zZg0rV67kkksuUSUfFIrPAQMVAH8GJgJzgJ3A78PbraarlkOlEOJCIcQKIcSK+vr63BYA4degOQ+A+Fr/VvSHgfZvi53VGz6GQk90rL03y+afBx98EJvNxmmnWS4DrVAoPmMMSABIKXdLKYNSyhCwiH4zTx0wxrRrDbAjwTnullLOl1LOLy8v130AOZ8I1u8DAGvzjoGhIRi7mDOHNRFrAtJfC2MWfPFkUQMIBoP85S9/YeHChVRUVGStXYVCMXIMKMRECFElpdwZfnsKYEQIPQ08LIS4GagGJgPvpHPOvUMD6M8DgPDqXpZKD8QqPubaQbEagPE+TgOwiABa9b9fStjiYFi2bBnbt2/nD3/4wzCcXaFQ5CIpBYAQYilwBFAmhKgDrgOOEELMQR/lNgPfBZBSrhFCPAZ8BASAS6WUwXQ6ktMCIKYctKEBJPMDRDSAsJoQMFX6jNUAIiYgd7QAsNIASvKGJy7/vvvuw+fzqWUeFYrPESkFgJTSyiB8b5L9bwBuyLQjuS0A9NdAjA8gWSSQTGICivcB6K+xJqC8LJmA6urqePzxx7n00ktxu7O3yphCoRhZciYT2GV3EQgFCMlQ6p1HiGBGPgAZtU8wlDgKSEtgAsrWko/33nsvwWCQyy67LCvtKRSK3CBnBIDTpps2clELMAbxSBioLQ0NIObVOBbi8wASmYAqCz0D7HH6hEIh7r//fo4++mjGjx8/7O0pFIrcQQmANDDs+LEaQHITkIx6DZoWe0mUCWwu9wxQVTT8GsCyZcvYsmUL55133rC3pVAocoucEQAum54ElYvlIPrt+IYPwIgCSnJMzGdmDSDOBxB+H1vjv9o3/BrA/fffT1FRESeffPKwt6VQKHKLnBEA+U59ucF2f/sI9ySeWDu+PY1EMLMP4P26lqj1fhNFAcUy3D6AlpYWnnjiCU4//XQ8nuEXNgqFIrfImUXhfW4fAG29bSPck3iMgd5cCgJ0DWBTQyc+jyMuPNOQDe9sauLE2/8T5fiNywMYIQGwdOlSenp6lPlHofickjMCoNBVCOSoAIh5bw4DPfJ3r1HotvP+z6MrXxsagD888zebi2KjgMzj/7r/0wuv9gVD5LuG7/ZIKbn77ruZM2cO8+bNG7Z2FApF7qIEQBrEOntjw0DbegJxxySrEmTY/DWhCwazCchY9nG4l39cuXIlq1ev5o477hj29YUVCkVukjM+AEMAtPa0jnBP4ok19adTDC7ZZ4bJ59yDx0edL5ssWrQIj8fDGWeckfW2FQpFbqA0gDSIHcrTKQWRLEnMGPCvPX46Vy+clnUB0N3dzSOPPMKpp56Kz+fLatsKhSJ3yBkB4HPlvhPYwFwMLhHJhINh8tE0gXMEZv9PPvkkbW1tnHvuuVlvW6FQ5A45YwJy293YNXuOCoDo92klgiXxAoyEycfM4sWLGTduHIcffviI9kOhUIwsOSMAhBAUugpp7c1BH0DMey2tWkCJPxvJ8X/79u28/PLLnH322Whaztx+hUIxAuTUCFDoKsxJDcA809dE/wCedF3gJJ/F1gLKJg8++CChUIizzz57xPqgUChyg5wSAD6XLycFgIyK4RcRG3466wFYkSjxa7iRUvLAAw+wYMECJk2aNCJ9UCgUuUNOCYBCVyEtPS0j3Y0oYh3AmhCRxC1zgbdUx5kZKR/AO++8w7p165TzV6FQAGkIACHEfUKIPUKID03bbhJCrBNCvC+E+LsQoii8vVYI0S2EWB3+d2cmnSn1ltLU3ZT5txhGYsdxIfqjeMwF3uKOS3LOkTIBPfDAA7jdbk499dQRaV+hUOQW6WgAi4FjY7a9BMyUUs4GPgauMX22QUo5J/zvokw6U+Ypo6GrIZNDhox/f9LAjpbuuO1xDmCTBmAu8BZLrpmAQqEQS5cu5atf/aqK/VcoFEAaAkBK+QbQFLPtRSmlUf/gbaBmKDpT6i2loashqflkuLj04VUsfnNz3PZ4E1CaGkAyJ/AIKACNjY20tLRwzjnnZL9xhUKRkwyFD+B84HnT+/FCiHeFEK8LIQ5NdJAQ4kIhxAohxIr6+noAyrxl9IX6RqQktD8Qoqcvfv362Jm87gTW/w4k0QCSybCRMAHt2LGD0aNHc9RRR2W9bYVCkZsMSgAIIX4KBICHwpt2AmOllPsBPwQeFkIUWh0rpbxbSjlfSjm/vLwc0AUAQGNX42C6NSBCUkYt3G5gJHRFHLeif+EWq/1jj7Mi2yag1tZWWlpa+OEPf4jNlp2F5hUKRe4zYAEghDgH+ApwhgzbO6SUvVLKxvDfK4ENwJR0z2kIgJHwA0hpPaM3ZvJepz5wCswmoIH5ALKtAezevQubTeOiizJyySgUis84AxIAQohjgR8DJ0opu0zby4UQtvDfE4DJwMZ0zzuiAoAEGkB4U55TL5tU5HVGTEDJfQCJ28pmGKjf76e+voGysjK8Xm/W2lUoFLlPymJwQoilwBFAmRCiDrgOPerHBbwUNoe8HY74OQz4hRAiAASBi6SUacd1jqQACEkIWAzohinH0ACKvY6IBpDMB5AsSzibJqBXXnmFQCBAeXlF1tpUKBR7BykFgJTyNIvN9ybY9wngiYF2ZlTeKAB2duwc6CkGjO4DSGwC8oQFgM/rjISB+pMIgGRkswTPI488wv772ygpKc5eowqFYq8gpzKBC1wFlHhK2NS8KavtSinDPoD4WbsxkzcWhI/WAJKUg07iBEi0CPxQ09zczGOPPUZ5eQVC5NStVigUOUDOjQrji8azqSXbAkB/tY4C0mnr7gOg2OvsFwDJSkEkaS9bJqC//OUv9PT0UF1dnZX2FArF3kXOCYDaolo2t2zOapvGLL8vqOcC3LHsU/wBfXA3hMNxs6oYVejinINrI05gfzINwMIH4HZoTCzPy1oU0MMPP8zs2bPJz8/PSnsKhWLvIucEwPii8Wxu2UxIDsy+PhCMoToYktz/n83c9MJ6lry1Wf8sPJBXF3lY/pOjGV+Wp8eCknki2KnzxvDKj44Ysn4nY+PGjbz99tucfvrpWWlPoVDsfeScAKgtqqU32Muezj1Za9OYrQeCMvJ3U6cf6B/IzVabdHwAVqUgshn++cgjjwDwrW99K2ttKhSKvYucEwAVeXq4YjZDQft9ACE8Dj3ap8uvl4UwhnGz4zaSCJahDyBbAiAYDHLPPfdw6KGHMm7cuKy0qVAo9j5yTgCUekuB7AqAiAYQkpFwz+6wADA+i9YA9NekUUAWGoA9SwLg6aefZtOmTfzgBz/ISnsKhWLvJOcEwEjUAzKCf/qCMpLw1enXi51GTECm/UUapSCsfADZ0gDuu+8+qqurOemkk7LSnkKh2DvJOQFQ6hk5DSAYCuGyR2sARiawiDIB6a/JSkFYpQFkQwDs3r2b559/nrPPPlsVflMoFEnJPQEwAiagiA8gKDGs96+s28Oqrc1JncBJcPfDHwAAIABJREFUNQALL0A2BMBDDz1EMBhUdf8VCkVKck4AuO1u8p35NHZnzwRkROz0hUJRM/ev/ulNkwko3gmcaRjocPsApJQsXryYAw88kGnTpg1rWwqFYu8n5wQA6Gag7JqA9NegKQzUwJjJm8dukUYimFUY6HAngK1evZoPPvhAzf4VCkVa5KQAKPOWZVUDiGQCh2SUBlBe4Iq8t84DyGw9gOHWABYvXozT6VSx/wqFIi1yUgBUFVSxrXVb1trrTwQLRRVxqyhwRWbyUSag8FVLuiKYpRN4+C633+/noYce4qSTTqK4WFX+VCgUqclJATC9bDofN35MIBRIvfMQYC4GZzYBjSp0J3UCJysHbekEHkYF4LnnnqOxsZFzzz13+BpRKBSfKXJWAPQGe7NWFjq6FET/9kK33SQA+kdv469MncA22/Bd7sWLF1NZWckxxxwzbG0oFIrPFmmNSEKI+4QQe4QQH5q2lQghXhJCfBJ+LQ5vF0KIW4UQnwoh3hdCzM20UzPKZwCwtmFtpocOCGOwDsZoAEFpygMw7S8GWAtouHwA9fX1PPvss5x55pnY7SnX+FEoFAogfQ1gMXBszLargVeklJOBV8LvARairwU8GbgQ+HOmnZpSqq8j/2nTp5keOiBCpjBQY+D2Om2EQjIiHMzm+0giWBIfgGUi2DCtA7BkyRICgYCK/lEoFBmRlgCQUr4BxK7texLwQPjvB4CTTduXSJ23gSIhRFUmnSpyF2HX7FkLBTUGeSn7s3sdNi1KI8g4DyBLiWDBYJA77riDQw45hJkzZw75+RUKxWeXwRilR0kpdwKEX41Vx0cD5hCeuvC2KIQQFwohVgghVtTX18d+poeCZqkekNnsY2T3OmyCQKh/GM80E9gyDHQYvMDPPvssmzZt4vvf//6Qn1uhUHy2GQ6vpNUoFzccSinvllLOl1LOLy8vjzug1FNKQ3d2NADzYG2sBGbXNEJSWjuB06gFZOUEHo61gG+99VZqamo4+eSTU++sUCgUJgYjAHYbpp3wq7GCSx0wxrRfDbAj05OXecuyZgIyawARAWATBEPSlAfQj5HRm7wa6PA7gdesWcMrr7zCJZdcgsPhGNJzKxSKzz6DEQBPA4bX8RzgKdP2s8PRQAcBrYapKBOyKQDMY7UR2++0hTWA8PZM1wPIRjno2267DbfbzXe+850hPa9Cofh8kFbMoBBiKXAEUCaEqAOuA24EHhNCfBvYCpwa3v054DjgU6ALOG8gHcuuAEimAejbM10RzGpBmKEUAM3NzSxZsoQzzjiDsrKyITuvQqH4/JCWAJBSnpbgo6Ms9pXApYPpFOg+gMauRqSUUfb34SBkoQHYtdgooH76fQAjtyTkvffeS3d3N//zP/8zZOdUKBSfL3IyExh0DSAog7T0tAx7W1Y+AIddi9IAMl0U3npJyKG53MFgkNtvv53DDz+cfffdd0jOqVAoPn/krACozK8EYGdHxu6DjLEUAJogKKXlimDGX8k0ACsVYKhqwT3zzDNs2bJFhX4qFIpBkbMCYKxvLEBWqoKaJ+vGoG63iahM4KgooEgewMhoALfeeitjx47lxBNPHJLzKRSKzyc5KwDG+PRI0q2tW4e9LasoIIdN0zUAizwAq0zg2LDP4fIBfPDBByxbtoxLL71U1f1RKBSDImcFQHVBNZrQsiIALPMANEEwlGBFsPBVM9cCis38Ha5F4W+77TY8Hg8XXHDBoM+lUCg+3+SsALBrdqoLqtnWNvwmILMA6A30awAh0wphqVYEi1tKchgSwRobG3nwwQc588wzKSkpGdS5FAqFImcFAOh+gC2tW4a9HctSELawE9iyGFz8cfECIL6dwWoA99xzDz09PSr0U6FQDAk5LQAmFk/MSklo82y9LxhCE/ryjcEUGkD0OWLeI+Nm/IPRAAKBAHfccQdHHnkks2bNGvB5FAqFwiCnBcCU0inUtdXR6e8c1nZiE8E0IbAJfYEYrMJALcbxYIzRPxQCj8MWtU0bhAB46qmn2LZtmwr9VCgUQ0bOCwAY/oVhYktBaEKgadGlIKzCQM3EmYCQuJ3RAmAwGsCtt95KbW0tJ5xwwoDPoVAoFGZyWgBMLZ0KwMeNHw9rO6GoPACJEPrqXSHZbwKyqgWU6BzGe7cj+vIO1AewevVq3njjDb73ve9hs9lSH6BQKBRpkNMCYFLJJGD4BYCVBmDTYspBW1QDTXQO/T247dGD9UAFwG233YbX6+X8888f0PEKhUJhRU4LgDxnHjWFNXzclD0NoDegO4E1TSQsB21VnC4+7l/isA1eA2hoaOChhx7i7LPPpri4OOPjFQqFIhE5LQBA9wMMvwnIrAEEw05gkXBNYIh3BMf6AEIyvvbPQEpBLFq0iN7eXhX6qVAohpzcFwAlWRYAwRCappuAAiEZqfjpiFnPN9YPYJUIFruPLcOy1sFgkDvvvJOjjjqKGTNmZHSsQqFQpCL3BUDpFJq6m4Z1cRgZ4wTW8wD0YnBGcTinPfpSxVpzYvMAQjJ+cWRbhovCv/jii2zdupXvfve7GR2nUCgU6TBgASCEmCqEWG361yaE+IEQ4udCiO2m7ccNpoMTSyYCsLF542BOkxRpKt0WDMl+J7CU/eWhY+z5sX6A+DDQ+H0yDQNdtGgR5eXlnHTSSRkdp1AoFOkwYAEgpVwvpZwjpZwDzENf/vHv4Y//YHwmpXxuMB0cXzQegE3NmwZzmqTEruwohEATglAoujqomdixPDYRTF/JDJ753iGmY9IXAHV1dTzzzDOce+65OJ3OtI9TKBSKdBkqE9BRwAYp5ZAX7qktqgVgc8vmoT51hNjZu24CgqCUkZr/rjgTUPRgbpxChusHSanvM6vGF9knEw3gxhtvBOCSSy5J+xiFQqHIhKESAN8Clpref08I8b4Q4j4hhGXsohDiQiHECiHEivr6+oQnLnAVUOopZVNL5hrAN+96i/HXPJtyv9gQTnMUUCITUCIn8GmL3uamF9YTkjLiA5hRVagfk6YA2L59O4sWLeK8886jtrY2rWMUCoUiUwYtAIQQTuBE4PHwpj8DE4E5wE7g91bHSSnvllLOl1LOLy8vT9rG+OLxA/IBLN/UZFmV06IvUe+NYnAAXf4AEO8ENsZ/Y1ZvCJFNDZ2s2dEW0QAAHv7OgTxx8cFp9/vKK69ESslPfvKTtI9RKBSKTBkKDWAhsEpKuRtASrlbShmUUoaARcABg21gZsVM3t31rmWN/aEgVgMQQmBM+H/57FogcRioYRoyNAB/IERDR6/+PnxIkdfJvHHpJXEtW7aMpUuX8tOf/lTN/hUKxbAyFALgNEzmHyFElemzU4APB9vAIWMOoaGrgXUN6wZ7KktkzAKONk3EmWsSOYFd4YqfhnDqDQsAiXXJiKT9kJKrr76ampoafvzjH2d2sEKhUGTIoASAEMILfAn4m2nzb4UQHwgh3geOBC4fTBsAh447FIB/b/33YE9lSbwPID5py5nAB9CvAejb/YEQjR1+QiEZlz2ciieffJJ33nmH66+/HrfbndGxCoVCkSmDWlVcStkFlMZsO2tQPbJgcslkfC4f7+56d6hPDVj5AERU3R4h4h24hnwwm4BCIUkgLAmau/xU+tIfxAOBAD/96U+ZNm0aZ5999kC+hkKhUGTEoARAthBCMHvUbN7f/f6wnD82DFSI6Cgfa9eDoQHoJqDO3gCdYYcxQH17L1U+T9p9ePbZZ1m7di2PPfYYdvtecVsUCsVezl4z0sweNZsl7y0JJ1gNbm3dWGITwWI1gGS4wjX/v/bnt5hQnhfZ3tYTsFw5LBF33XUX1dXVnHLKKekfpFAoFIMg52sBGcweNZt2fztbW7cO+bnjE8FSCwCPU7905gSxjfXRS1emK6g2b97MP//5T7797W+r2b9Cocgae40AmFis1wQajoxgY/g3YvqFSF27P9/lAMDtSLxCV7pRQIsWLUIIwQUXXJDeAQqFQjEE7DUCwCgJMZCM4FQYTmAj2cvIBE5Gvksf+GNLRJhJZ/zv6+vjvvvu47jjjmPs2LHpdVihUCiGgL1GAIzxjUEghkUDMEI4jVh/qzyAWPJcuqnGZU+mAaQWAU8//TS7du1SJZ8VCkXW2WsEgNPmZHTh6AEJgFQZxKE4DQBsKa6MIQBiS0SYSccFcNdddzFmzBgWLlyYemeFQqEYQvYaAQC6GWhD84aMj4st1RyL8bGR7GWUg05GQVgAGAvGmDHKRqRyAm/YsIGXXnqJCy64AJstsSahUCgUw8FeJQDmV83nv9v/S1dfV0bHBVNoAIaGYAzcmiBSBjoRhgbQ7Q/GfWbE/6dSABYtWoTNZuPb3/52ij0VCoVi6NmrBMDCyQvpDfby2ubXMjouNs4//vN4J7DVzN6MIQC6LATA6KLUCWB+v5/777+fE044gdGjR6fcX6FQKIaavUoAHDbuMDShsbxueUbHBVJIAGOubziBNSEi6wAk4oDaEgBmji6M+2xcqRfQy0Ek4sknn2TPnj3K+atQKEaMvUoAuO1uRheMZnPr5oyOS6kBGD4Au+EDsLbtmzlkchlvXfNFjp1ZGffZuFI9I3hXW0/C4xctWkRtbS3HHHNM8s4pFArFMLFXCQDQHcGZrg+cUgMwooBMGkBvCg0AdFt/bJlogNqwBrCr1VoA1NfX8+qrr3LWWWehaXvdLVAoFJ8R9rrRZ3zx+IyTwVI5gWPDQG1aahOQQUVBfMVPQwNI5Eh+8sknCYVCfO1rX0urDYXi/9u79+ioqnuB49/fTN4hApEEiHDRWECQAtFAjKIXESpatUWggF4uVSzUSouAF1BcoGUplVULqCzUC4i1IhUfVwyK9QJqobe8AyQgIaCW9yMkQEjIY2bfP+bMZPIiYTJhJpnfZ62sM+ecfc6c2VlzfnP2U6nG0PQCQKvrOHLuCKWO2svXq6pvM9Bwe0URUH1n8EqIi6y2ra5hoD/66COSk5Pp2bNnvd5DKaUagz/mBP7emgAmU0S2WtviReRLEdlvLet3N62H5NbJGAwHztS/P0DdAaBqM1Dhji4J7JzpKp//9y61z1lc05hB7uEhUmsIIgUFBaxdu5YHH3zQ76OaKqXU5fDX0JN3GmNOe61PB9YaY/4gItOtdb/McZjSLgWA7ce20y2hW72O8Q4A3x4/R/uW0bSMDvdsM55KYFdnLPc9vWVMOHt/P7jafMB1iQizsff3gwmr4biMjAzKysq0+EcpFXCNVQT0M+Bt6/XbwM/9deJuCd2IDotm69Gt9T7GOwAMnv93Ri+p3IzUXQkc6dUPwC06wk5YXeNCVBFmE6Ij7DVWEH/44YckJSXRt2/fyzqnUkr5mz8CgAH+JiLbRGScta2tMeYYgLVMrHqQiIwTka0isvXUqVP1frMwWxgp7VPYeuzyA4B7uevwWbKOnKXAaqfvjg8xEXb3tdX73ABDUq6ptKzt+Ly8PD777DOGDx+urX+UUgHnjyKg24wxR0UkEfhSRL6tz0HGmDeBNwFSU1MvXUhfxc3tb2bpjqU4nA7strrH0HG3AvJu2XPfqxvo2jaOLybd4akDcPfure84/m4vD+/FS0N7EmYTXhpae8XusmXLKC0t5ZFHHrm8N1BKqUbQ4J+hxpij1vIk8DHQFzghIu0BrOXJhr6Pt9SkVC6UXWBf3r56pS+3mmOWlFcetmHfifOA1xOANblL1RnC6mKzCRFhNs+yJgUFBbzwwgvcdddd9OrV67LOr5RSjaFBAUBEYkUkzv0a+AmQBawCxljJxgCfNOR9qkpNSgVgy5Et9UrvvqHX1rnLNc+wq7z/UukaYsmSJeTn5zN37ly/n1sppXzR0CeAtsAGEdkJbAZWG2PWAH8ABonIfmCQte43Xa/uSkJMAp/nfl6v9OXWT/ySstoCgKvi1z29o78DQHFxMQsWLKBfv37cdNNNfj23Ukr5qkF1AMaYg0C18gxjTB5wV0POfSl2m52h3Yby511/pqisiJjwmEumd4/2WbUIyLPfGGwC0Y0UAGbOnMmhQ4dYtmyZX8+rlFIN0WSbovzixl9QVFbE6pzVdab1PAHUcmN3GlfLHU8RUFnNgcIX69at449//CO//vWvGTBggN/Oq5RSDdVkA8Adne6gbWxb3t/zfp1pnbUEAHdrTeN+ArACQH3HAapLaWkpzzzzDElJScybN88v51RKKX9psgHAbrMzrPswVuesprC08JJpy2spArJbEcBVBCSeIqCLfnoCmDx5Mps2beLll18mKurS4wMppdSV1mQDALiKgYrLi8nIyai2z3sieEctrYDc4/g4jWv6Rn/WAWzfvp2FCxcyadIkRo4c2eDzKaWUvzXpANDv3/rRvkV7/pr912r7vId/cDhqbgXkDgDuVkD+bAa6cOFCYmJimDVrVoPPpZRSjaFJBwCb2BjefTif7/+csxfPVtrnqPEJoPYiIKnUCsj3IiCn08m0adNYunQpY8aMoWXLlj6fSymlGlPQBICColI+yTxy2ceN7jWaEkcJyzKXVdru3ZnXUUslsM3zBGCw2SqeAGqbyKUuxhgmTJjA3LlzGT9+PAsWLPDpPEopdSUETQCYuCKTiSsy+Vde0WUdl5qUSnqHdF7Z/AoOZ8Uv90pFQLUEgDCvOgDvSmBflJaW8qtf/YpFixYxbdo0Fi1aRHh4eN0HKqVUgARNADic77rxlzouv/jlyVue5GD+QVbvr+gTUKkIyFl9MDioeAJwdwSL8jEAnDhxggEDBrBkyRKeffZZ5syZo5O9KKWCXtAEAPf9uo7Ju2o05IYhdLiqAws2VRS5GK97vaPOZqAAUuPsXnXZsWMHffr0Yfv27axYsYLZs2frzV8p1SQETwCwlr60wQ+3h/Ob1N+w7rt1fJfvmjC+pieAqq2AbFU6ggEkt4nlmXtvqNf7FhYWcvfdd2OMYcOGDYwYMeKyr10ppQIlaAKAe8TO4lLfWuAMun4Q4JoqEqrUAdTSD6DMSuNuBgqw7qn+jLvj+nq954svvsipU6d4//33dZA3pVSTEzQBwP2DvdjHXrjdE7pjExu7T+62zlcRALb9kM8X2cerFQGVOVwBoczpvOzin/nz5zNnzhzGjBlDenq6T9eslFKBFDwBwCoEuljLkM11iQmP4UfxP2LXiV1A5SKgD7YdZvw726o9AbgniikudXimg6yPFStWMGnSJIYOHcrixYt9ul6llAq04AkA1v26IePw9Enqw/rv13Om+EylIiC3qnUAhSXlrNp5lOIyh6cPQF2cTiezZs0iJSWF5cuXExbmj1k1lVLqygu6AOBrERDA9H7TOVdyjtlfz6amWR23/XCm2rbnV2VTXOqodxPQr7/+mpycHKZMmUJERITP16qUUoHmcwAQkY4isl5E9opItohMtLY/JyJHRCTT+rv3cs7bkCeAHok9eLT3oyzcspDv8g9W2/99XhER9sofOe9CKeculte7E9gHH3xAdHQ0Q4YM8fk6lVIqGDTkCaAcmGKM6QbcAjwhIt2tffOMMb2tv8/qczJPK6AGDsX8/J3PY7fZWbBlTo37B93Yttq2w2eK6lUH4HQ6+fjjj7nnnnuIibn0LGRKKRXsfA4Axphjxpjt1uvzwF7gGl/P5y6zv+hjM1CADftPs+WA4Xd9f8dH+5ZTbMuslia5TWy1bedL6vcE8M9//pNjx44xdOhQn69RKaWChV/qAETkWiAF2GRtmiAiu0RkqYi0ruWYcSKyVUS2njp1ytP+/2IDhmL+jyWbmLgik+f6P8d1rTqTF74AJxcrpalaBOQWVY8ngHfeeYfw8HB++tOf+nyNSikVLBocAESkBfAh8KQx5hywCLge6A0cA16u6ThjzJvGmFRjTGpEi1acLykHfO8I5i06PJrf3jwDh+0UZfJDpX1htQSAup4A9u/fz+LFixk7dqwO8ayUahYaFABEJBzXzf9dY8xHAMaYE8YYhzHGCfw30Leu8/zrTMUIoP6ajjGpRScAHFIAuEb+fGdsX8LtNXf4qqsOYMaMGURGRuoEL0qpZqMhrYAEWALsNcb8yWt7e69kQ4CsyzlvQyuB3VpHtQHAIfkAvDoqhds7J9Q6UNulmoFu3ryZlStXMmXKFNq1a+eX61NKqUBryBPAbcBoYECVJp9zRWS3iOwC7gQm1ftipO4ngCMFxcz6JMszjENNHE5Dq6gE12srAMREujpsVR0S2u1SRUDz5s0jPj6ep5566pLXppRSTYnP3ViNMRtwzaVeVb2afVb1+5/dyCeZRz1PAN+fvsDSjd8x877ulcrtZ3+6hzXZx+l/QyJ3dk2s8VxFpeXYJQKbaYHYC6C8IrDUGgBqKQK6ePEiGRkZjBo1iri4OF8+mlJKBaWgGccgMS6ShBaR5Jw8D8Cz/5PFhtzT3N8riT7XxgPwSeYR1mQfB+BMYWml470HfysudeA0BrtpTdckJ2ktk7ijs+uJwD3hzJj0ThQUl1FS5mRN9vEa6wCMMTz33HMUFhYyfPhw/39opZQKoKAZCiIhLooubVvwQ14R7276gQ25pwHI87rRT1xR0a7/xPnKzTu9B5ErLnPgdBpspjXFjjwWjEypNt9v+1bRLBiZwrVWv4CqdQDGGB5//HFeeuklxo0bx8CBA/34aZVSKvCCJgAkxkXSuW0cDqdhxscV9cbuqSKrOnSm8vYLpeWe10WlDhzGEGYS+e5sDiXlJZ597iKgcKtYKTEuEqhcB2CM4eGHH+aNN95g2rRpvP766zrLl1Kq2QmKABAbEUZCXCRd2lYvY3c/ESz+e+WxffafKKy0fqGkcgBwOiHWcTvnSwvIyMnw7HMPOREZZgWAq6wA4FUE9O677/Lee+8xa9Ysnd9XKdVsBUUdQHJCLFHhdq5tU318nQOnCvl019Fqlbdbf8jnq30n6W9VBF8oqWg95K4DiHL2pn1sR+ZsmMOD3R5ERHhyYBfKHIZhN3cA4Lbr2zCqb0d6JLk6d+Xn5zN58mTS0tKYOXOm3vyVUs1WUDwBuEWG2YkKr3xJ/ziQR0FRGUVePYSvaRVNTISdr/ad8mwrqlQEVI7DGAQ741Kmsu3YNtZ9tw6A+NgI5jz4Y0+Zf+vYCOY82JPoCDslJSVMmDCBvLw8Xn/9dWy2oMoepZTyq6C7w9VnUDYR6Nw2jpwT5z3bCr2KgNyVwAD3JA8lLiKOv+z+yyXPefToUfr06cPy5cuZOnUqvXv39vETKKVU0xB0AaCmHrmtY8IrrTudhi6JLfjHgTzue/XvrP/2ZKUA8Oq6XF74bC8AsRExjOwxkhVZKzh09lCN72mMYdSoURw4cIBVq1bx4osv+vETKaVUcAq6AND2qijP6+Q2sTze/3qeubdbpTTlTsM1raMByDpyjknvZ/LpzqOe/bknCzl46gLgelqYcfsMjDE8u/7Zau93/vx55s6dyzfffMP8+fO5//77tdxfKRUSgi4AvPZQCvf3SgKgRVQY0wbfwO1WJ64Iq+VOi6gwfpHakcf6XUfGb/tRXOrgi+wTDOxWfbIXu03o1KoTE9Mm8s7Od8g87upLsGbNGoYNG0ZCQgLTp0/n1ltv5dFHH71Cn1IppQJPTE2T515hqampZuvWrZ51Ywyvrcvl5ynX0DE+BmMMr67L5f5eSXyedYx7e7T3dOAC+N89J/h011HG3ZHM+m9dLYO+yD5OflEpM++7kYgwGwUXC7j+levpaOtIx687kpGRQWJiIiNGjGDEiBGkp6c320rfHTv6A5CS8lVAr0Mp5V8iss0Yk+rz8cEYAPzt3LlzrFy5kufXP8+hzoeI/0s8k385malTpxIeHl73CZo4DQBKNU8NDQDN8yevJTs7m9GjR9OuXTsee+wxwrPDEYTk/0pm/KTxIXHzV0qp2gRFRzB/OX36NJs3byY3N5f9+/ezfPlyysvLGT16NI888ghpaWm8l/UeY1eNZej7Q1k/Zj02adYxUCmlatUkA8CFCxfYtWsX2dnZZGVlkZOTQ25uLgcPHsRhjfYZFxdHr169ePvtt0lOTvYc+9CPH6KkvIRHVz3K2FVjmX/3fFpG6RSPSqnQE/QBoKioiD179rB792527NjBxo0b2blzp+dGHxMTQ5cuXejduzejRo1i0KBBdO3alTZt2tTanPOXvX/JzhM7eW3za6zOWc34m8fzRN8naNdCZ/tSSoWORqsEFpHBwALADiw2xvyhtrTuSuDS0lK2b99OZmYmmZmZbNy4kezsbM9Y/7GxsaSlpXHrrbfSt29fevToQadOnXxuvbPlyBZmfzObjJwM2rVoR9ZvsoiPjvfpXMFMK4GVap6CshWQiNiBHGAQcBjYAowyxuypKX23bt3MwIEDeeutt7hwwdWB66qrriI9PZ20tDR69uxJz549SU5Oxm6ve6iIy7Xp8Cb6vdWPzvGdGXLDENI6pNHl6i7Npn7g9MHR2MTGLan/F+hLUUr5UbAGgHTgOWPM3db60wDGmDm1pDdhYWE89NBDPPDAA/Tp04eOHTte0R65q3NWM+urWWQez8Rh/DMxfbCY18u1nLEnptkENaUUFD5TGJQBYBgw2BjzmLU+GkgzxkzwSjMOGGet9gCyqp0oNLUBTgf6IoKE5kUFzYsKmhcVuhpjfJ6svLEqgWv66V4p0hhj3gTeBBCRrQ2JYs2J5kUFzYsKmhcVNC8qiEiDetA2VnnAYaCj13oH4GgtaZVSSgVAYwWALUBnEblORCKAkcCqRnovpZRSPmiUIiBjTLmITAC+wNUMdKkxJvsSh7zZGNfRRGleVNC8qKB5UUHzokKD8iIoBoNTSil15WmbQKWUClEaAJRSKkQFPACIyGAR2SciuSIyPdDX09hEZKmInBSRLK9t8SLypYjst5atre0iIq9YebNLRG4K3JX7n4h0FJH1IrJXRLJFZKK1PeTyQ0SiRGSziOy08uJ5a/t1IrLJyou/Wo0qEJFIaz3X2n9tIK/f30TELiI7RCSMGePAAAADHElEQVTDWg/JfAAQke9FZLeIZLqbffrrOxLQAGANGbEQuAfoDowSke6BvKYrYBkwuMq26cBaY0xnYK21Dq586Wz9jQMWXaFrvFLKgSnGmG7ALcAT1v8/FPOjBBhgjOkF9AYGi8gtwEvAPCsv8oGxVvqxQL4x5kfAPCtdczIR2Ou1Hqr54HanMaa3V/8H/3xHjDEB+wPSgS+81p8Gng7kNV2hz30tkOW1vg9ob71uD+yzXr+Bawylauma4x/wCa7xo0I6P4AYYDuQhqvHa5i13fN9wdXCLt16HWalk0Bfu58+fwfrpjYAyMDVsTTk8sErP74H2lTZ5pfvSKCLgK4BDnmtH7a2hZq2xphjANYy0doeMvljPbqnAJsI0fywij0ygZPAl8ABoMAYU24l8f68nryw9p8Frr6yV9xo5gNTAae1fjWhmQ9uBvibiGyzhtABP31HAj0fQJ1DRoS4kMgfEWkBfAg8aYw5d4lBAJt1fhhjHEBvEWkFfAx0qymZtWyWeSEi9wEnjTHbRKS/e3MNSZt1PlRxmzHmqIgkAl+KyLeXSHtZ+RHoJwAdMsLlhIi0B7CWJ63tzT5/RCQc183/XWPMR9bmkM0PAGNMAfAVrnqRViLi/qHm/Xk9eWHtbwmcubJX2ihuAx4Qke+BFbiKgeYTevngYYw5ai1P4vph0Bc/fUcCHQB0yAiXVcAY6/UYXGXh7u3/adXs3wKcdT/2NQfi+qm/BNhrjPmT166Qyw8RSbB++SMi0cBAXJWg64FhVrKqeeHOo2HAOmMV+jZlxpinjTEdjDHX4rofrDPGPEyI5YObiMSKSJz7NfATXCMn++c7EgQVHPfimjzmADAj0NdzBT7ve8AxoAxXtB6Lq8xyLbDfWsZbaQVXK6kDwG4gNdDX7+e86Ifr8XQXkGn93RuK+QH0BHZYeZEFzLS2JwObgVxgJRBpbY+y1nOt/cmB/gyNkCf9gYxQzgfrc++0/rLd90h/fUd0KAillApRgS4CUkopFSAaAJRSKkRpAFBKqRClAUAppUKUBgCllApRGgCUUipEaQBQSqkQ9f/I67s0Z9OFjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rolling_average = np.convolve(rewards, np.ones(100)/100)\n",
    "\n",
    "plt.plot(rewards)\n",
    "plt.plot(rolling_average, color='black')\n",
    "plt.axhline(y=195, color='r', linestyle='-') #Solved Line\n",
    "#Scale Epsilon (0.001 - 1.0) to match reward (0 - 200) range\n",
    "eps_graph = [200*x for x in epsilons]\n",
    "plt.plot(eps_graph, color='g', linestyle='-')\n",
    "#Plot the line where TESTING begins\n",
    "plt.axvline(x=TRAIN_END, color='y', linestyle='-')\n",
    "plt.xlim( (0,EPISODES) )\n",
    "plt.ylim( (0,220) )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "envCartPole.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changes**  \n",
    "*hyper parameters*: You can alter alpha, gamma, batch size, and episode length to see what differences the algorithm returns.  \n",
    "*Training End*: You can also change the line where I only check the last 5 runs before switching to testing mode (if len(rewards) > 5 and np.average(rewards[-5:]) > 195:) as that doesn't prove it was solved. The reason I did this was because I wanted to limit the amount of runs I made.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**  \n",
    "This is a Deep Q-Network implementation. There are some changes you can make here and there but it follows the paper. Hopefully, you were able to understand the code as well as make your own version to compare with this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Reference**  \n",
    "Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Petersen, S. (2015). *Human-level control through deep reinforcement learning*. Nature, 518(7540), 529"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gdg_denver] *",
   "language": "python",
   "name": "conda-env-gdg_denver-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
